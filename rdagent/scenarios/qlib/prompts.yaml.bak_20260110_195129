hypothesis_and_feedback: |-
  =========================================================
  {% for experiment, feedback in trace.hist %}
  # Trial {{ loop.index }}:
  ## Hypothesis
  {{ experiment.hypothesis }}
  ## Specific task:
  {% for task in experiment.sub_tasks %}
  {% if task is not none and task.get_task_brief_information is defined %}
  {{ task.get_task_brief_information() }}
  {% endif %}
  {% endfor %}
  ## Backtest Analysis and Feedback:
  {% if experiment.result is not none %}
  Backtest Result: {{ experiment.result.loc[["IC", "1day.excess_return_without_cost.annualized_return", "1day.excess_return_without_cost.max_drawdown"]] }}
  {% endif %}
  Observation: {{ feedback.observations }}
  Hypothesis Evaluation: {{ feedback.hypothesis_evaluation }}
  Decision (Whether the hypothesis was successful): {{ feedback.decision }}
  =========================================================
  {% endfor %}

last_hypothesis_and_feedback: |-
  ## Hypothesis
  {{ experiment.hypothesis }}
  ## Specific task:
  {% for task in experiment.sub_tasks %}
  {% if task is not none and task.get_task_brief_information is defined %}
  {{ task.get_task_brief_information() }}
  {% endif %}
  {% endfor %}
  ## Backtest Analysis and Feedback:
  {% if experiment.result is not none %}
  Backtest Result: {{ experiment.result.loc[["IC", "1day.excess_return_without_cost.annualized_return", "1day.excess_return_without_cost.max_drawdown"]] }}
  {% endif %}
  Training Log:
  Here, you need to focus on analyzing whether there are any issues with the training. If any problems are identified, you must correct them in the next iteration and clearly describe how the changes will be made in the hypothesis.
  {{ experiment.stdout }}
  Observation: {{ feedback.observations }}
  Evaluation: {{ feedback.hypothesis_evaluation }}
  Decision (Whether this experiment is SOTA): {{ feedback.decision }}
  New Hypothesis (Given in feedback stage, just for reference, and can be accepted or rejected in the next round): {{ feedback.new_hypothesis }}
  Reasoning (Justification for the new hypothesis): {{ feedback.reason }}

sota_hypothesis_and_feedback: |-
  ## Hypothesis
  {{ experiment.hypothesis }}
  ## Specific task:
  {% for task in experiment.sub_tasks %}
  {% if task is not none and task.get_task_brief_information is defined %}
  {{ task.get_task_brief_information() }}
  {% endif %}
  {% endfor %}
  ## Backtest Analysis and Feedback:
  {% if experiment.result is not none %}
  Backtest Result: {{ experiment.result.loc[["IC", "1day.excess_return_without_cost.annualized_return", "1day.excess_return_without_cost.max_drawdown"]] }}
  {% endif %}
  Training Log: {{ experiment.stdout }}
  Observation: {{ feedback.observations }}
  Evaluation: {{ feedback.hypothesis_evaluation }}
  Decision (Whether this experiment is SOTA): {{ feedback.decision }}

hypothesis_output_format: |-
  The output should follow JSON format. The schema is as follows:
  {
  "hypothesis": "An exact, testable, and innovative statement derived from previous experimental trace analysis. Avoid overly general ideas and ensure precision. The hypothesis should clearly specify the exact approach and expected improvement in performance in two or three sentences. **All natural-language content here must be written in concise professional Chinese.**",
  "reason": "Provide a clear, logical explanation for why this hypothesis was proposed, grounded in evidence (e.g., trace history, domain principles). Reason should be short with no more than two sentences. **All natural-language content here must be written in concise professional Chinese.**",
  }

factor_hypothesis_output_format: |-
  The output should follow JSON format. The schema is as follows:
  {
  "hypothesis": "The new hypothesis generated based on the information provided. Limit in two or three sentences. **All natural-language content here must be written in concise professional Chinese.**",
  "reason": "The reason why you generate this hypothesis. It should be comprehensive and logical. It should cover the other keys below and extend them. Limit in two or three sentences. **All natural-language content here must be written in concise professional Chinese.**",
  }

hypothesis_output_format_with_action: |-
  The output should follow JSON format. The schema is as follows:
  {
  "action": "If `hypothesis_specification` provides the action you need to take, please follow "hypothesis_specification" to choose the action. Otherwise, based on previous experimental results, suggest the action you believe is most appropriate at the moment. It should be one of [`factor`, `model`].",
  "hypothesis": "The new hypothesis generated based on the information provided,should be a string. **All natural-language content here must be written in concise professional Chinese.**",
  "reason": "The reason why you generate this hypothesis. It should be comprehensive and logical. It should cover the other keys below and extend them. Limit in two or three sentences. **All natural-language content here must be written in concise professional Chinese.**",
  }

model_hypothesis_specification: |-
  1. First, observe and analyze the overall experimental progression in `hypothesis_and_feedback`. Analyze where the previous model designs were inadequate — whether it was due to parameter settings, architectural flaws, or a lack of novelty (proposing entirely new concepts is highly encouraged as long as they demonstrate effectiveness).
  2. Second, `last_hypothesis_and_feedback` and `sota_hypothesis_and_feedback` are key references you should pay close attention to. You can choose to optimize based on either of them or generate new ideas to form hypotheses and experiments.
  3. If there is no prior experiment or result available at the beginning, you can start by implementing a simple and small architecture.
  4. If a series of attempts fail to achieve SOTA, consider exploring entirely new directions; at this point, it is acceptable to return to simple architectures.
  5. Focus exclusively on the architecture of PyTorch models. Each hypothesis should specifically address architectural decisions, such as layer configurations, activation functions, regularization methods, and overall model structure. DO NOT do any feature-specific processing. Instead, you can propose innovative transformations on the input time-series data to enhance model training effectiveness.
  6. Avoid including aspects unrelated to architecture, such as input features or optimization strategies.
  7. Sometimes, when training performance is poor, adjusting hyperparameters can also be an effective strategy for improvement.
  8. Use standard libraries for baseline models, but also explore custom architecture designs to investigate novel structures. After sufficient trials with traditional models, aim for innovation comparable to top-tier AI conferences (NeurIPS, ICLR, ICML, SIGKDD, etc.) in time series modeling.

factor_hypothesis_specification: |-
  1. **Factors per Generation（不再限制数量）：**
    - 每一轮可以给出 **任意数量** 的候选因子（按你的策略/预算决定），以支持整体量化演进，而不是只做少量因子试探。
    - 在给出多个因子时，请在类型、数据来源和结构上保持一定多样性，避免高度相似的微调版本。
  2. **Simple and Effective Factors First:**
    - Start with factors that are simple, easy to achieve and likely effective.
    - Concisely explain why these factors are expected to work.
    - Avoid complex or combined factors initially.
  3. **Gradual Complexity Increase:**
    - Introduce more complex factors (e.g. machine learning based factors, factors use mult-dimentional factor raw data, etc.) as more experimental results are gathered.
    - Combine factors only after simpler ones are tested and validated.
  4. **New Directions and Optimizations:**
    - If multiple consecutive iterations fail to produce factors surpassing SOTA, consider switching to a new direction and can starting with simple factors again.
    - If optimizing a specific type of factor, proceed from simple to complex.
  5. **Data Source Constraints (非常重要)：**
    - 你必须优先使用当前回测数据中已经提供的 **静态/资金流因子表**，尤其是 `static_factors.parquet` 中的字段（例如主力资金、北向资金、行业/规模相关特征等）。
    - 在每一轮因子设计中，**至少设计 2 个因子必须直接依赖静态或资金流相关字段**（例如来自 static_factors 或 moneyflow 的字段），不得全部只依赖日频价量 (`open/high/low/close/volume/amount`)。
    - 设计因子时，只能使用已经在数据侧真实存在的字段名，禁止编造新的字段名称；如果不确定字段是否存在，应避免使用。
  6. **Avoid Trivial Price-Volume Replication（避免平庸价量重复）：**
    - 当前 SOTA 因子库已经广泛覆盖了基于日频价量的动量、波动率、成交量放大、K 线形态等传统信号。请避免再设计与这些因子在形式上高度类似的指标，例如简单的 `past N-day return`、`volume spike`、`moving average crossover` 等轻微变体。
    - 新因子应当在 **数据来源**（如资金流、行业/市值、持股结构、静态风格暴露等）或 **数学结构**（如非线性组合、比率结构、归一化方式）上相对于现有 SOTA 因子有明显差异，而不是对已有信号做线性变换或简单平移缩放。
  7. **Diversification & Dissimilarity（增强差异性）：**
    - 在同一轮中生成的多个因子之间，应尽量减少高度同质化的设计，避免只是改变窗口长度或简单参数（例如仅将 10 日动量改成 20 日动量）。
    - 新因子的一个重要目标是：在横截面上与典型价量动量/成交量类因子不要过高相关。你可以通过引入静态资金面、风格/行业暴露、风险因子等信息来降低与传统价量信号的线性相关性。
  8. Note
    - Highlight that factors surpassing SOTA are included in the library to avoid re-implementation.
    - No matter how many factors you plan to generate, only reply with one set of hypothesis and reason. The hypothesis can include the proposal of multiple factors at the same time.

factor_experiment_output_format: |-
  The output should follow JSON format. The schema is as follows:
  {
      "factor name 1": {
          "description": "description of factor 1, start with its type, e.g. [Momentum Factor]",
          "formulation": "latex formulation of factor 1",
          "variables": {
              "variable or function name 1": "description of variable or function 1",
              "variable or function name 2": "description of variable or function 2"
          }
      },
      "factor name 2": {
          "description": "description of factor 2, start with its type, e.g. [Machine Learning based Factor]",
          "formulation": "latex formulation of factor 2",
          "variables": {
              "variable or function name 1": "description of variable or function 1",
              "variable or function name 2": "description of variable or function 2"
          }
      }
      # Don't add ellipsis (...) or any filler text that might cause JSON parsing errors here!
  }

model_experiment_output_format: |-
  So far please only design one model to test the hypothesis!
  The output should follow JSON format. The schema is as follows (value in training_hyperparameters is a basic setting for reference, you CAN CHANGE depends on the previous training log):
  {
    "model_name (The name of the model)": {
        "description": "A detailed description of the model",
        "formulation": "A LaTeX formula representing the model's formulation",
        "architecture": "A detailed description of the model's architecture, e.g., neural network layers or tree structures",
        "variables": {
            "\\hat{y}_u": "The predicted output for node u",
            "variable_name_2": "Description of variable 2",
            "variable_name_3": "Description of variable 3"
        },
        "hyperparameters": {
            "hyperparameter_name_1": "value of hyperparameter 1",
            "hyperparameter_name_2": "value of hyperparameter 2",
            "hyperparameter_name_3": "value of hyperparameter 3"
        },
        "training_hyperparameters" {  # All values are for reference; you can set them yourself
            "n_epochs": "20",
            "lr": "1e-3",
            "early_stop": 5,
            "batch_size": 256,
            "weight_decay": 1e-4,
        }
        "model_type": "Tabular or TimeSeries"  # Should be one of "Tabular" or "TimeSeries"
    },
  }

factor_feedback_generation:
  system: |-
    You are a professional financial result analysis assistant in data-driven R&D.
    The task is described in the following scenario:

    {{ scenario }}

    In this test scenario, the user is mainly interested in improving an **A-share long-only stock selection strategy** on **daily data over a multi-year backtest window**, with the following requirements:
      - Investment universe: all A-share stocks listed on the Shanghai Stock Exchange (SSE) and Shenzhen Stock Exchange (SZSE), **excluding all ST and *ST stocks，以及所有已退市或当前暂停上市的股票**。当前回测所使用的 Qlib bin 数据集和 HDF5 日线行情快照，均已在数据导出阶段完成上述过滤，确保研究与回测在同一可交易股票池上进行。
      - Portfolio construction: on each rebalancing date, **select exactly 30 stocks** from the eligible universe and build an **equal-weighted long-only portfolio** (no short selling, no leverage).
      - Holding period: a medium-term horizon of **5–20 trading days** for each position on a **daily trading frequency**; in practice, if a single position reaches **+10% profit** before 5 trading days, it can be taken profit and closed early, and if the unrealized loss reaches **-10%**, a stop-loss should be triggered and the position should be closed immediately.
      - Performance target: over the backtest period, the typical 5–20 day holding-period return should be **around 5%–10%**, while the **maximum portfolio drawdown should be no greater than 10%** (the smaller, the better).
      - The strategy should primarily rely on cross-sectional and time-series information from price, volume and volatility, and may combine multiple factors (multi-factor stock selection).
    When giving feedback and summarizing results in this scenario, please pay special attention to these constraints and explicitly comment on how the current experiment moves the strategy closer to or away from these goals.
    All final textual explanations and natural-language summaries in your feedback should be written in **Chinese** (use concise professional Chinese), while keeping JSON keys and numeric values unchanged.

    You will receive a hypothesis, multiple tasks with their factors, their results, and the SOTA result.
    Your feedback should specify whether the current result supports or refutes the hypothesis, compare it with previous SOTA (State of the Art) results, and suggest improvements or new directions.

    Please understand the following operation logic and then make your feedback that is suitable for the scenario:
      1. Logic Explanation:
        a) All factors that have surpassed SOTA in previous attempts will be included in the SOTA factor library.
        b) New experiments will generate new factors, which will be combined with the factors in the SOTA library.
        c) These combined factors will be backtested and compared against the current SOTA to enable continuous iteration.
      2. Development Directions:
        a) New Direction: Propose a new factor direction for exploration and development.
        b) Optimization of Existing Direction:
          - Suggest further improvements to that factor (this can include further optimization of the factor or proposing a direction that combines better with the factor).
          - Avoid re-implementing previous factors as those that surpassed SOTA are already included in the factor library and will be used in each run.
      3. Final Goal: To continuously accumulate factors that surpass each iteration to maintain the best SOTA.

    When judging the results:
      1. Any small improvement should be considered for inclusion as SOTA (set `Replace Best Result` as yes).
      2. If the new factor(s) shows an improvement in the annualized return, recommend it to replace the current best result.
      3. Minor variations in other metrics are acceptable as long as the annualized return improves.

    Consider Changing Direction for Significant Gaps with SOTA:
      - If the new results significantly differ from the SOTA, consider exploring a new direction (write new type factors).
      - Avoid re-implementing previous factors as those that surpassed SOTA are already included in the factor library and will be used in each run.

    Please provide detailed and constructive feedback for future exploration.
    Respond in JSON format. Example JSON structure for Result Analysis:
    {
      "Observations": "Your overall observations here",
      "Feedback for Hypothesis": "Observations related to the hypothesis",
      "New Hypothesis": "Your new hypothesis here",
      "Reasoning": "Reasoning for the new hypothesis",
      "Replace Best Result": "yes or no"
    }

    重要实现约束规则（必须严格遵守）：
      1. 依赖与导入相关：
        - 不要导入 h5py 模块。保存 HDF5 文件时，只允许使用 pandas.DataFrame.to_hdf 接口，代码中不需要也不允许显式 import h5py。
        - 不要引入当前环境中不一定存在的第三方库（例如额外的深度学习框架、数据库驱动等），除非在本项目中已明确使用并保证已安装。优先使用标准库、numpy、pandas、torch 等常用基础依赖。
      2. 异常处理相关：
        - 在因子实现函数中，禁止使用 try/except 包裹整个主逻辑。出现错误时应直接抛出，由外层 RD-Agent/QLib 框架捕获和记录日志。
        - 只有在极少数需要精细处理的局部逻辑中，才可以使用小范围的 try/except，但不得吞掉异常信息或返回静默的错误结果。
      3. 数据来源与示例数据相关：
        - 因子实现必须基于框架传入的数据（例如 QLib 提供的 DataFrame），不允许在实现中使用 np.random 等方式构造完全随机的演示数据作为真实价格序列。
        - 如果需要示例，请仅在注释或说明中给出，不在实际执行代码路径中生成虚拟数据。
      4. 滚动窗口与 min_periods 设置：
        - 使用 rolling(window=...) 计算移动平均、波动率、动量等因子时，min_periods 应与窗口长度一致，或不显式设置（使用默认值），以避免在样本数量不足时返回不可靠的数值。
        - 对于窗口长度内不足的数据（前若干天），允许保留为 NaN，后续由回测引擎或上层逻辑自然处理这些缺失值，不要为了“填满数据”随意填充虚假值。
      5. 接口规范与可执行性：
        - 必须严格遵守 RD-Agent/QLib 约定的因子函数签名，不要修改函数名、入参、返回类型。
        - 生成的代码必须能够在无额外手工修改的情况下，直接在当前 RD-Agent 环境中执行，不依赖人工删除 import、try/except 或手工改动逻辑。
      6. Pandas API 使用约束：
        - 不要虚构 pandas 中不存在的方法（例如在 Rolling 对象上使用不存在的 combine 等方法）。
        - 计算相关系数、协方差等统计量时，应优先使用 pandas 提供的标准接口，例如 Series.rolling().corr()、cov() 等，而不是自定义不存在的 API。
        - 如果不确定某个 API 是否存在，请改用已知、基础的 pandas/numpy 操作组合实现，不要编造新方法名。

  user: |-
    Target hypothesis:
    {{ hypothesis_text }}
    Tasks and Factors:
    {% for task in task_details %}
      - {{ task.factor_name }}: {{ task.factor_description }}
        - Factor Formulation: {{ task.factor_formulation }}
        - Variables: {{ task.variables }}
        - Factor Implementation: {{ task.factor_implementation }}
        {% if task.factor_implementation == "False" %}
        **Note: This factor was not implemented in the current experiment. Only the hypothesis for implemented factors can be verified.**
        {% endif %}
    {% endfor %}
    Combined Results:
    {{ combined_result }}

    Analyze the combined result in the context of its ability to:
    1. Support or refute the hypothesis.
    2. Show improvement or deterioration compared to the SOTA experiment.

    Note: Only factors with 'Factor Implementation' as True are implemented and tested in this experiment. If 'Factor Implementation' is False, the hypothesis for that factor cannot be verified in this run.

model_feedback_generation:
  system: |-
    You are a professional quantitative analysis assistant in top-tier hedge fund.

    The task is described in the following scenario:
    {{ scenario }}

    In this test scenario, the user is mainly interested in improving an **A-share long-only stock selection strategy** on **daily data over a multi-year backtest window**, with the following requirements:
      - Investment universe: all A-share stocks listed on the Shanghai Stock Exchange (SSE) and Shenzhen Stock Exchange (SZSE), **excluding all ST and *ST stocks**.
      - Portfolio construction: on each rebalancing date, **select exactly 30 stocks** from the eligible universe and build an **equal-weighted long-only portfolio** (no short selling, no leverage).
      - Holding period: a medium-term horizon of **5–20 trading days** for each position (for implementation, you can adopt a fixed holding period such as 10 or 20 days in the backtest framework).
      - Performance target: over the backtest period, the typical 5–20 day holding-period return should be **around 5%–10%**, while the **maximum portfolio drawdown should be no greater than 10%** (the smaller, the better).
      - The strategy should primarily rely on cross-sectional and time-series information from price, volume and volatility, and may combine multiple factors (multi-factor stock selection).
    When analyzing model performance, explicitly evaluate whether these objectives are being met or approached.
    All narrative parts of your feedback and final summary should be written in **Chinese** (concise professional Chinese), while JSON structure and field names must remain in English.

    You will receive a quantitative model hypothesis, its specific task description, and it market backtest result.
    Your feedback should specify whether the current result supports or refutes the hypothesis, compare it with previous SOTA results, examine the model's training logs to analyze whether there are issues with hyperparameter settings, and suggest improvements or new directions.

    Please provide detailed and constructive feedback.
    Example JSON Structure for Result Analysis:
    {
      "Observations": "First analyze the model's training logs to determine whether there are any issues with its parameter settings. Then clearly summarize the current results and the SOTA results with exact scores and any notable patterns. Limit your summary to no more than three concise, data-focused sentences.",
      "Feedback for Hypothesis": "Explicitly confirm or refute the hypothesis based on specific data points or performance trends. Limit to two sentences.",
      "New Hypothesis": "Propose a revised hypothesis, considering observed patterns and limitations in the current one. Limit to no more than two sentences.",
      "Reasoning": "Explain the rationale for the new hypothesis using specific trends or performance shifts. Be concise but technically complete. Limit to two sentences.",
      "Decision": <true or false>,
    }

    重要实现约束规则（必须严格遵守）：
      1. 依赖与导入相关：
        - 不要导入 h5py 模块。保存 HDF5 文件时，只允许使用 pandas.DataFrame.to_hdf 接口，代码中不需要也不允许显式 import h5py。
        - 不要引入当前环境中不一定存在的第三方库（例如额外的深度学习框架、数据库驱动等），除非在本项目中已明确使用并保证已安装。优先使用标准库、numpy、pandas、torch 等常用基础依赖。
      2. 异常处理相关：
        - 在模型实现函数中，禁止使用 try/except 包裹整个主逻辑。出现错误时应直接抛出，由外层 RD-Agent/QLib 框架捕获和记录日志。
        - 只有在极少数需要精细处理的局部逻辑中，才可以使用小范围的 try/except，但不得吞掉异常信息或返回静默的错误结果。
      3. 数据来源与示例数据相关：
        - 模型实现必须基于框架传入的数据（例如 QLib 提供的 DataFrame 或特征矩阵），不允许在实现中使用 np.random 等方式构造完全随机的演示数据作为真实价格或特征序列。
        - 如果需要示例，请仅在注释或说明中给出，不在实际执行代码路径中生成虚拟数据。
      4. 接口规范与可执行性：
        - 必须严格遵守 RD-Agent/QLib 约定的模型接口和函数签名，不要修改函数名、入参、返回类型。
        - 生成的代码必须能够在无额外手工修改的情况下，直接在当前 RD-Agent 环境中执行，不依赖人工删除 import、try/except 或手工改动逻辑。
      5. Pandas API 使用约束：
        - 不要虚构 pandas 中不存在的方法（例如在 Rolling 对象上使用不存在的 combine 等方法）。
        - 当模型内部需要做时间序列统计（如 rolling 相关性、协方差等）时，应优先使用 pandas 提供的标准接口，例如 Series.rolling().corr()、cov()，而不是自定义不存在的 API。
        - 如果不确定某个 API 是否存在，请改用已知、基础的 pandas/numpy 操作组合实现，不要编造新方法名。

  user: |-
    {% if sota_hypothesis %}
    # SOTA Round Information:
    Hypothesis: {{ sota_hypothesis.hypothesis }}
    Specific Task: {{ sota_task }}
    Code Implementation: {{ sota_code }}
    Result: {{ sota_result }}
    {% else %}
    # This is the first round. No previous information available. As long as the performance is not too negative (eg.ICIR is greater than 0), treat it as successful. Do not set the threshold too high.
    {% endif %}

    # Current Round Information:
    Hypothesis: {{ hypothesis.hypothesis }}
    Why propose this hypothesis: {{ hypothesis.reason }}
    Specific Task: {{ exp.sub_tasks[0].get_task_information() }}
    Code Implementation: {{ exp.sub_workspace_list[0].file_dict.get("model.py") }}
    Training Log: {{ exp.stdout }}
    Result: {{ exp_result }}

    # When judging the results:
    1. **Recommendation for Replacement:**
      - If the new model's performance shows an improvement in the annualized return, recommend it to replace the current SOTA result.
      - Minor variations in other metrics are acceptable as long as the annualized return improves.
    2.  Consider Changing Direction When Results Are Significantly Worse Than SOTA:
      - If the new results significantly worse than the SOTA, consider exploring a new direction, like change a model architecture.

action_gen:
  system: |-
    Quantitative investment is a data-driven approach to asset management that relies on mathematical models, statistical techniques, and computational methods to analyze financial markets and make investment decisions. Two essential components of this approach are factors and models.

    You are one of the most authoritative quantitative researchers at a top Wall Street hedge fund. I need your expertise to develop new factors and models that can enhance our investment returns. Based on the given context, I will ask for your assistance in designing and implementing either factors or a model.

    In the current testing scenario, the user is mainly interested in improving an **A-share long-only stock selection strategy** on **daily data over a multi-year backtest window**, with the following requirements:
      - Investment universe: all A-share stocks listed on the Shanghai Stock Exchange (SSE) and Shenzhen Stock Exchange (SZSE), **excluding all ST and *ST stocks，以及所有已退市或当前暂停上市的股票**。研究因子所用的 HDF5 日线数据与回测所用的 Qlib bin 数据集在股票池上已经对齐，均只包含上述过滤后的可交易股票。
      - Portfolio construction: on each rebalancing date, **select exactly 30 stocks** from the eligible universe and build an **equal-weighted long-only portfolio** (no short selling, no leverage).
      - Holding period: a medium-term horizon of **5–20 trading days** for each position on a **daily trading frequency**; in practice, if a single position reaches **+10% profit** before 5 trading days, it can be taken profit and closed early, and if the unrealized loss reaches **-10%**, a stop-loss should be triggered and the position should be closed immediately.
      - Performance target: over the backtest period, the typical 5–20 day holding-period return should be **around 5%–10%**, while the **maximum portfolio drawdown should be no greater than 10%** (the smaller, the better).
      - The strategy should primarily rely on cross-sectional and time-series information from price, volume and volatility, and may combine multiple factors (multi-factor stock selection).
    When deciding whether the next experiment should focus on factors or models, please consider which action is more likely to move the strategy towards these goals (higher 5–20 day holding-period return under the constraint of max drawdown ≤ 10%, and respecting the **+10% take-profit / -10% stop-loss** rules at the single-position level).

    You will receive a series of experiments, including their factors and models, and their results.
    Your task is to analyze the previous experiments and decide whether the next experiment should focus on factors or models.

    Example JSON Structure for your return:
    {
      "action": "factor" or "model",  # You must choose one of the two
    }

  user: |-
    {% if hypothesis_and_feedback|length == 0 %}
    It is the first round of hypothesis generation. The user has no hypothesis on this scenario yet.
    {% else %}
    The former hypothesis and the corresponding feedbacks are as follows:
    {{ hypothesis_and_feedback }}
    {% endif %}


    {% if last_hypothesis_and_feedback != "" %}
    Here is the last trial's hypothesis and the corresponding feedback. The main feedback includes a new hypothesis for your reference only. You should evaluate the entire reasoning chain to decide whether to adopt it, propose a more suitable hypothesis, or transfer and optimize it for another scenario (e.g., factor/model), since transfers are generally encouraged:
    {{ last_hypothesis_and_feedback }}
    {% endif %}
