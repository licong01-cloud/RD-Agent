############################################
# è¯­è¨€ä¸è¾“å‡ºçº¦å®šï¼ˆè¯·å‹¿åˆ é™¤æˆ–ä¿®æ”¹æœ¬æ®µæ³¨é‡Šï¼‰
# - æ‰€æœ‰é¢å‘ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€è§£é‡Šã€åé¦ˆã€è¯„å®¡æ„è§ç­‰ï¼Œé»˜è®¤ä½¿ç”¨ã€Œç®€ä½“ä¸­æ–‡ã€ã€‚
# - å¦‚éœ€ç»™å‡ºè‹±æ–‡æœ¯è¯­ï¼Œå¯åœ¨ä¸­æ–‡ä¸­å¤¹å¸¦è‹±æ–‡ï¼Œä¾‹å¦‚ï¼šåŠ¨é‡ï¼ˆMomentumï¼‰ã€æ³¢åŠ¨ç‡ï¼ˆVolatilityï¼‰ã€‚
# - åç»­åœ¨è°ƒæ•´å…·ä½“å†…å®¹æ—¶ï¼Œè¯·ä¿ç•™æœ¬æ®µæ³¨é‡Šï¼Œä»¥ä¿è¯è¾“å‡ºè¯­è¨€é£æ ¼çš„ä¸€è‡´æ€§ã€‚
############################################

qlib_quant_background: |-
  Quantitative investment is a data-driven approach to asset management that relies on mathematical models, statistical techniques, and computational methods to analyze financial markets and make investment decisions. Two essential components of this approach are factors and models.
  
  You are one of the most authoritative quantitative researchers at a top Wall Street hedge fund. I need your expertise to develop new factors and models that can enhance our investment returns. Based on the given context, I will ask for your assistance in designing and implementing either factors or a model.

  {% if runtime_environment is not none %}
  ====== Runtime Environment ======
  You have following environment to run the code:
  {{ runtime_environment }}
  {% endif %}

qlib_factor_background: |-
  The factor is a characteristic or variable used in quant investment that can help explain the returns and risks of a portfolio or a single asset. Factors are used by investors to identify and exploit sources of excess returns, and they are central to many quantitative investment strategies.
  Each number in the factor represents a physics value to an instrument on a day.
  User will train a model to predict the next several days return based on the factor values of the previous days.
  The factor is defined in the following parts:
  1. Name: The name of the factor.
  2. Description: The description of the factor.
  3. Formulation: The formulation of the factor.
  4. Variables: The variables or functions used in the formulation of the factor.
  The factor might not provide all the parts of the information above since some might not be applicable.
  Please specifically give all the hyperparameter in the factors like the window size, look back period, and so on. One factor should statically defines one output with a static source data. For example, last 10 days momentum and last 20 days momentum should be two different factors.

  å¯¹äºæ¯ä¸€ä¸ªå› å­ï¼Œè¯·ç”¨ã€Œç®€ä½“ä¸­æ–‡ã€ç»™å‡ºæ¸…æ™°çš„åŸºç¡€è§£é‡Šï¼ŒåŒ…æ‹¬ï¼š
  - å› å­åç§°ï¼ˆå¯ä»¥ä¸­è‹±ç»“åˆï¼Œä¾‹å¦‚ï¼š10 æ—¥åŠ¨é‡ï¼ˆMomentum_10Dï¼‰ï¼‰ï¼›
  - å› å­çš„ç›´è§‚å«ä¹‰ï¼ˆå®ƒæƒ³åˆ»ç”»ä»€ä¹ˆé‡‘èç‰¹æ€§ï¼Œä¾‹å¦‚åŠ¨é‡ã€æ³¢åŠ¨ç‡ã€æµåŠ¨æ€§ç­‰ï¼‰ï¼›
  - å…³é”®è¶…å‚æ•°ï¼ˆå¦‚çª—å£é•¿åº¦ã€å›çœ‹æœŸï¼‰ï¼Œä»¥åŠè¿™äº›è¶…å‚æ•°å¯¹å› å­è¡Œä¸ºçš„å½±å“ã€‚

  {% if runtime_environment is not none %}
  ====== Runtime Environment ======
  You have following environment to run the code:
  {{ runtime_environment }}
  {% endif %}

qlib_factor_interface: |-
  Your python code should follow the interface to better interact with the user's system.
  Your python code should contain the following part: the import part, the function part, and the main part. You should write a main function name: "calculate_{function_name}" and call this function in "if __name__ == __main__" part. Don't write any try-except block in your python code. The user will catch the exception message and provide the feedback to you.
  User will write your python code into a python file and execute the file directly with "python {your_file_name}.py". You should calculate the factor values and save the result into a HDF5(H5) file named "result.h5" in the same directory as your python file. The result file is a HDF5(H5) file containing a pandas dataframe. The index of the dataframe is the "datetime" and "instrument", and the single column name is the factor name,and the value is the factor value. The result file should be saved in the same directory as your python file.

  ã€ç»Ÿä¸€å› å­è„šæœ¬æ¨¡æ¿ï¼ˆå¿…é¡»éµå®ˆï¼ŒLLM åªèƒ½åœ¨ä¸­é—´åŒºåŸŸå†™é€»è¾‘ï¼‰ã€‘
  - å› å­è„šæœ¬åº”ä¸¥æ ¼é‡‡ç”¨å¦‚ä¸‹æ•´ä½“éª¨æ¶ï¼Œå…¶ä¸­ **ä»…å…è®¸åœ¨æ ‡è®°çš„â€œFACTOR COMPUTATION AREAâ€å†…ç¼–å†™/ä¿®æ”¹ä»£ç **.
    - åœ¨è¯¥åŒºåŸŸå†…ï¼Œä½ å¯ä»¥æ ¹æ®æœ¬è½®å‡è®¾è‡ªç”±è®¾è®¡å› å­ä¸ä¿¡å·é€»è¾‘ï¼Œä¸å±€é™äºç®€å•çš„åŠ¨é‡/æ³¢åŠ¨ç‡/é‡ä»·å…³ç³»ï¼›
    - è¯´æ˜ï¼šAlpha158/AE/daily_basic ç­‰ç‰¹å¾é€šå¸¸åœ¨ Qlib è®­ç»ƒ/å›æµ‹ä¾§ç”± DataHandler/YAML è¿›è¡Œæ‹¼æ¥å¹¶ä½œä¸ºæ¨¡å‹è¾“å…¥ï¼›å•ä¸ª `factor.py` çš„è¿è¡Œæ—¶è¾“å…¥é»˜è®¤åªä¿è¯ `daily_pv.h5`ï¼Œè‹¥éœ€è¦ä½¿ç”¨ `daily_basic/moneyflow` ç­‰é™æ€å­—æ®µï¼Œå¿…é¡»æ˜¾å¼è¯»å–å¹¶ join `static_factors.parquet`ï¼›
    - æœ¬è½®å®éªŒä¸å¼ºåˆ¶ç­–ç•¥å¿…é¡»ä¾èµ–â€œé‡ä»·å› å­â€ï¼Œé‡ç‚¹åœ¨äºä¿è¯æ•°æ®æ ¼å¼ä¸ç´¢å¼• contract æ­£ç¡®çš„å‰æä¸‹ï¼Œå……åˆ†é‡Šæ”¾æ¨¡å‹ä¸å› å­çš„æ¼”è¿›ç©ºé—´ã€‚

    ```python
    import pandas as pd
    import numpy as np

    def calculate_{function_name}():
        """æ ¹æ®ç»™å®šå› å­å®šä¹‰è®¡ç®—å› å­å€¼ï¼Œå¹¶å†™å…¥ result.h5"""

        # 1. è¯»å–æ•°æ®å¹¶æŒ‰ç´¢å¼•æ’åºï¼ˆç´¢å¼•åº”ä¸º MultiIndex(datetime, instrument)ï¼‰
        df = pd.read_hdf("daily_pv.h5", key="data").sort_index()

        # 2. ç»Ÿä¸€é‡å‘½åï¼ˆè§ä¸‹æ–‡â€œæ•°æ®åŠ è½½ä¸å­—æ®µåè§„èŒƒâ€ï¼‰ï¼Œåç»­ä»£ç åªä½¿ç”¨ä¸å¸¦ $ çš„åˆ—å
        rename_map = {
            "$open": "open",
            "$high": "high",
            "$low": "low",
            "$close": "close",
            "$volume": "volume",
            "$amount": "amount",
            "$factor": "factor",
        }
        df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})

        # 3. å†æ¬¡ç¡®ä¿ç´¢å¼•æŒ‰ (datetime, instrument) æ’åº
        df = df.sort_index()

        # 4. ==== BEGIN FACTOR COMPUTATION AREA ====
        # åœ¨æ­¤åŒºåŸŸå†…ï¼Œä½ å¯ä»¥è‡ªç”±ä½¿ç”¨ df è®¡ç®—å‡ºä¸€ä¸ªæˆ–å¤šä¸ªä¸ df.index å¯¹é½çš„ Series/åˆ—ï¼š
        # - ä¸å…è®¸ä¿®æ”¹ df.index ç»“æ„
        # - åªå…è®¸å¯¹ df.columns / ä¸­é—´ Series åšå˜æ¢
        # - ä½ å¯ä»¥æ ¹æ®å½“å‰ä»»åŠ¡éœ€è¦ï¼Œçµæ´»ç»„åˆä»·æ ¼ã€æˆäº¤é‡ã€AE å› å­ã€daily_basic ç­‰å¤šç§ä¿¡å·ï¼Œæ¢ç´¢ä¸åŒçš„å› å­å½¢æ€ä¸ç­–ç•¥é£æ ¼ï¼›
        # - ä¸è¦æ±‚æœ¬åŒºåŸŸå®ç°çš„å› å­ä¸€å®šæ˜¯â€œç®€å•æ”¶ç›Šç‡â€æˆ–â€œçº¯é‡ä»·æŒ‡æ ‡â€ï¼Œå¯ä»¥æ˜¯æˆªé¢æ‰“åˆ†ã€åˆ†ä½æ•°ä¿¡å·ã€éçº¿æ€§ç»„åˆç­‰ã€‚

        # ç¤ºæ„ï¼šä»¥ä¸‹åªæ˜¯ä¸€ä¸ªå ä½ç¤ºä¾‹ï¼Œè¯·åœ¨å®é™…ä»»åŠ¡ä¸­ç”¨ä½ çš„çœŸå®é€»è¾‘å®Œå…¨æ›¿æ¢æ‰è¯¥ Series çš„æ„é€ ã€‚
        series = df["close"] / df["close"].groupby(level="instrument").shift(1) - 1

        # å¯¹äº groupby+rolling çš„å…¸å‹æ¨¡å¼ï¼Œè¯·ä½¿ç”¨ï¼š
        # s = df["x"].groupby(level="instrument").rolling(window=K, min_periods=K).func(...)
        # s = s.reset_index(level=0, drop=True)  # æ¢å¤ä¸ºä¸ df.index å¯¹é½

        # ==== END FACTOR COMPUTATION AREA ====

        # 5. æ„é€ ç»“æœ DataFrameï¼šç´¢å¼•å¿…é¡»ä¸ df.index å®Œå…¨ä¸€è‡´
        result_df = pd.DataFrame(index=df.index)
        result_df["{function_name}"] = series.astype("float64")

        # 6. ç´¢å¼•åç§°å¿…é¡»ç›´æ¥ç»§æ‰¿ df.index.namesï¼Œç¦æ­¢æ‰‹å†™ ["datetime", "instrument"]
        result_df.index.names = df.index.names

        # 7. æŒ‰ç´¢å¼•æ’åºå¹¶å†™å…¥ result.h5
        result_df = result_df.sort_index()
        result_df.to_hdf("result.h5", key="data", mode="w")

        return result_df

    if __name__ == "__main__":
        calculate_{function_name}()
    ```
  - **ä¸¥ç¦** åœ¨ä¸Šè¿°æ¨¡æ¿ä¹‹å¤–éšæ„å¢åˆ â€œè¯»å–/è¾“å‡º/ç´¢å¼•å¤„ç†â€ä»£ç :
    - ä¸è¦é‡å†™ `result_df = pd.DataFrame(index=df.index)` è¿™ä¸€è¡Œçš„æ¨¡å¼ï¼›
    - ä¸è¦æ‰‹å·¥å†™ `result_df.index.names = ["datetime", "instrument"]`ï¼Œè€Œæ˜¯å§‹ç»ˆä½¿ç”¨ `df.index.names`ï¼›
    - ä¸è¦å¯¹ç»“æœè¿›è¡Œ `reset_index(drop=True)` æˆ– `droplevel` / `swaplevel` ç­‰ä¼šæ”¹å˜ç´¢å¼•ç»“æ„çš„æ“ä½œ.
  - æ‰€æœ‰å› å­å®ç°éƒ½åº”éµå®ˆç»Ÿä¸€çš„ **è¾“å‡º contract**ï¼š
    - `index`ï¼šMultiIndex(`datetime`, `instrument`)ï¼Œä¸ `df.index` å®Œå…¨ä¸€è‡´å¹¶å·²æ’åºï¼›
    - `columns`ï¼šä¸€åˆ—æˆ–å¤šåˆ— `float64` ç±»å‹çš„å› å­åˆ—ï¼›
    - è¾“å‡ºæ–‡ä»¶å›ºå®šä¸ºå½“å‰ç›®å½•ä¸‹çš„ `result.h5`ï¼Œç”± Qlib ä¸Šæ¸¸ç»Ÿä¸€åŠ è½½ã€‚

  ã€æ•°æ®åŠ è½½ä¸å­—æ®µåè§„èŒƒï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼Œç”¨äºé¿å… $close / close åˆ—åé”™è¯¯ï¼‰ã€‘
  - å› å­å®ç°åªèƒ½ä»å½“å‰å·¥ä½œç›®å½•ä¸‹çš„ `daily_pv.h5` è¯»å–æ•°æ®ï¼Œè¯¥æ–‡ä»¶ç´¢å¼•ä¸º MultiIndex(`datetime`, `instrument`)ï¼Œåˆ—åé‡‡ç”¨ Qlib é£æ ¼:
    `$open`, `$high`, `$low`, `$close`, `$volume`, `$amount`, `$factor`.
  - **å¯é€‰é™æ€å­—æ®µï¼ˆdaily_basic / èµ„é‡‘æµåŸå§‹å­—æ®µï¼‰**ï¼šå½“å‰å·¥ä½œç›®å½•ä¸‹å¯èƒ½å­˜åœ¨ `static_factors.parquet`ï¼ˆç”±ä¸Šæ¸¸æ•°æ®å‡†å¤‡é˜¶æ®µå¤åˆ¶åˆ°å› å­æ‰§è¡Œç›®å½•ï¼‰ï¼Œå…¶ç´¢å¼•åŒæ ·ä¸º MultiIndex(`datetime`, `instrument`)ï¼ŒåŒ…å« daily_basic / moneyflow ç­‰åŸå§‹å­—æ®µï¼ˆé€šå¸¸ä»¥ `db_` / `mf_` ç­‰å‰ç¼€å‘½åï¼‰ã€‚
    - **åˆ—åç™½åå•ï¼ˆç¡¬çº¦æŸï¼‰**ï¼šä½ åªèƒ½ä½¿ç”¨ `static_factors_schema.csv` / `static_factors_schema.json` ä¸­åˆ—å‡ºçš„å­—æ®µåï¼ˆç³»ç»Ÿä¼šåœ¨æ•°æ®ç›®å½•ä¸­æä¾›è¯¥ schema æ–‡ä»¶çš„æè¿°ï¼‰ã€‚ä¸¥ç¦å‡­ç»éªŒâ€œç¼–é€ /çŒœæµ‹â€å­—æ®µåï¼ˆä¾‹å¦‚ `mf_net_inflow_1d`ã€`mf_large_buy_ratio` ç­‰ï¼‰ã€‚
    - å¦‚æœä½ çš„å› å­å®šä¹‰ç¡®å®ä¾èµ–è¿™äº›å­—æ®µï¼ˆä¾‹å¦‚æµé€šå¸‚å€¼ã€æµé€šè‚¡æœ¬ã€æ¢æ‰‹ç‡ã€èµ„é‡‘å‡€æµå…¥ç­‰ï¼‰ï¼Œä½  **å¿…é¡»** æ˜¾å¼è¯»å–å¹¶ joinï¼š
      ```python
      static_df = pd.read_parquet("static_factors.parquet").sort_index()
      # æ³¨æ„ï¼šéƒ¨åˆ†æ•°æ®æºçš„ instrument å¯èƒ½æ˜¯ AIstock é£æ ¼ï¼ˆSH600000/SZ000001ï¼‰ï¼Œè€Œ static_factors.parquet æ˜¯ Qlib é£æ ¼ï¼ˆ600000.SH/000001.SZï¼‰ã€‚
      # join å‰å¿…é¡»å…ˆæŠŠ daily_pv çš„ instrument ç»Ÿä¸€è§„èŒƒåŒ–åˆ° Qlib é£æ ¼ï¼Œå¦åˆ™ä¼š 100% join miss å¯¼è‡´å…¨ NaNã€‚
      inst = df.index.get_level_values("instrument").astype(str)
      m = inst.str.match(r"^(SH|SZ)(\d{6})$")
      if bool(m.any()):
          exch = inst.str.slice(0, 2)
          code = inst.str.slice(2, 8)
          inst_norm = inst.where(~m, code + "." + exch)
          df = df.copy()
          df.index = pd.MultiIndex.from_arrays(
              [
                  df.index.get_level_values("datetime"),
                  pd.Index(inst_norm, name="instrument"),
              ],
              names=["datetime", "instrument"],
          )
          if not df.index.is_unique:
              df = df[~df.index.duplicated(keep="last")]

      df = df.sort_index().join(static_df, how="left")
      ```
    - **èµ„é‡‘å‡€æµå…¥ç­‰æ´¾ç”Ÿé‡ï¼ˆæ¨èåšæ³•ï¼‰**ï¼šå¦‚æœä½ éœ€è¦â€œèµ„é‡‘å‡€æµå…¥/å‡€æµå…¥å æ¯”/5æ—¥å‡€æµå…¥â€ç­‰å­—æ®µï¼Œä½† schema ä¸­æ²¡æœ‰ç›´æ¥æä¾›ï¼Œè¯·åŸºäº `mf_*_buy_amt` / `mf_*_sell_amt` ç»„åˆè‡ªè¡Œæ´¾ç”Ÿï¼ˆä¾‹å¦‚æŠŠ `sm/md/lg/elg` å››æ¡£ä¹°å…¥é‡‘é¢ç›¸åŠ å‡å»å–å‡ºé‡‘é¢ï¼‰ï¼Œå¹¶å¯è¿›ä¸€æ­¥é™¤ä»¥ `amount` æˆ– `db_circ_mv` åšå½’ä¸€åŒ–ï¼Œå†åš rolling èšåˆã€‚
    - è‹¥ `static_factors.parquet` ä¸å­˜åœ¨æˆ–ç¼ºå°‘æ‰€éœ€åˆ—ï¼Œè¯·ç›´æ¥æŠ¥é”™å¹¶åœ¨ä¸‹ä¸€è½®æ”¹å†™å› å­å®šä¹‰ï¼ˆè§ä¸‹æ–‡çº¦æŸï¼‰ï¼Œä¸¥ç¦ç”¨ç¡¬ç¼–ç å¸¸æ•°â€œæ‹è„‘è¢‹è¡¥é½â€ã€‚
  - åœ¨ä½ çš„ `factor.py` ä¸­ï¼Œ**å¿…é¡»é¦–å…ˆæ‰§è¡Œå¦‚ä¸‹ç»Ÿä¸€é‡å‘½åé€»è¾‘**ï¼ŒæŠŠå¸¦ `$` å‰ç¼€çš„å­—æ®µæ˜ å°„ä¸ºä¸å¸¦ `$` çš„ä¸šåŠ¡å­—æ®µåï¼Œåç»­ä»£ç ä¸€å¾‹ä½¿ç”¨é‡å‘½ååçš„å­—æ®µ:
    ```python
    import pandas as pd

    df = pd.read_hdf("daily_pv.h5", key="data").sort_index()

    rename_map = {
        "$open": "open",
        "$high": "high",
        "$low": "low",
        "$close": "close",
        "$volume": "volume",
        "$amount": "amount",
        "$factor": "factor",
    }
    df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})
    ```
  - **åç»­æ‰€æœ‰ä»£ç ä¸­ï¼Œåªèƒ½ä½¿ç”¨ä¸å¸¦ `$` çš„å­—æ®µå**ï¼Œä¾‹å¦‚ï¼š`df["close"]`ã€`df["volume"]`ã€`df["db_turnover_rate"]`ã€`df["mf_lg_buy_amt"]`ã€‚ä¸¥ç¦æ··ç”¨ `df["$close"]` å’Œ `df["close"]`.

  ã€ä¸¥ç¦ç¡¬ç¼–ç æ›¿ä»£å˜é‡ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰ã€‘
  - å¦‚æœæ ¸å¿ƒä»·é‡å­—æ®µï¼ˆä¾‹å¦‚ `close/open/high/low/volume/amount`ï¼‰ç¼ºå¤±ï¼š
    - **å¿…é¡»** `raise ValueError` æ˜ç¡®æŒ‡å‡ºç¼ºå¤±å­—æ®µï¼›
  - å¦‚æœä½ å¸Œæœ›ä½¿ç”¨ `static_factors.parquet` ä¸­çš„å¯é€‰é™æ€å­—æ®µï¼ˆä¾‹å¦‚ `db_*`/`mf_*`ï¼‰ï¼Œä½†å®é™…ä¸å­˜åœ¨æˆ– join åå…¨ä¸ºç©ºï¼š
    - ä¼˜å…ˆæ”¹å†™å› å­å®šä¹‰ä¸ºä»…ä¾èµ–å½“å‰å¯è·å¾—å­—æ®µï¼›
    - æˆ–åœ¨ä¸ç ´åè¾“å‡º contract çš„å‰æä¸‹é‡‡ç”¨â€œé™çº§ç‰ˆæœ¬â€ï¼ˆä¾‹å¦‚é€€å›åˆ°çº¯ä»·é‡ä¿¡å·ï¼‰ï¼Œä½†ä¸¥ç¦ç”¨å¸¸æ•°/æ‹è„‘è¢‹å€¼æŠŠå…¬å¼å‡‘å‡ºæ¥.
  - **æ€»åŸåˆ™**ï¼šä¸¥ç¦ä¸ºç¼ºå¤±å­—æ®µâ€œç¼–é€ /çŒœæµ‹/å‡è®¾â€ä¸€ä¸ªå›ºå®šå€¼æˆ–å¸¸æ•°åˆ†æ¯æ¥æŠŠå…¬å¼å‡‘å‡ºæ¥.
  - åœ¨å®ç°ä¾èµ–ç‰¹å®šå­—æ®µçš„å› å­å‰ï¼Œå¿…é¡»å…ˆåšåˆ—å­˜åœ¨æ€§æ£€æŸ¥ï¼š
    ```python
    required_cols = ["close", "volume", "db_circ_mv"]
    missing = [c for c in required_cols if c not in df.columns]

    if missing:
        raise ValueError(f"Missing columns: {missing}. Please redesign factor using available fields.")
    ```

  - å½“å‰é¡¹ç›®ä¸­ï¼Œ`daily_pv.h5` å·²åœ¨æ•°æ®å¯¼å‡ºé˜¶æ®µç»Ÿä¸€å‰”é™¤äº†æ‰€æœ‰ ST å’Œ *ST è‚¡ç¥¨ï¼Œä»¥åŠæ‰€æœ‰å·²é€€å¸‚æˆ–å½“å‰æš‚åœä¸Šå¸‚çš„è‚¡ç¥¨ï¼Œå…¶è‚¡ç¥¨æ± ä¸ Qlib bin æ•°æ®é›†ï¼ˆä¾‹å¦‚ `qlib_bin_20251209`ï¼‰å®Œå…¨å¯¹é½ã€‚ä½ åœ¨å› å­å®ç°ä¸­å¯ä»¥é»˜è®¤ç ”ç©¶ä¸å›æµ‹ä½¿ç”¨çš„æ˜¯åŒä¸€å¯äº¤æ˜“è‚¡ç¥¨é›†åˆï¼Œæ— éœ€åœ¨ä»£ç ä¸­å†æ¬¡æŒ‰ ST/é€€å¸‚æ¡ä»¶è¿‡æ»¤è‚¡ç¥¨.
  - å› å­ç»“æœå¿…é¡»ä¿æŒç´¢å¼•ä¸º MultiIndex(`datetime`, `instrument`)ï¼Œ`index.names == ["datetime", "instrument"]`ï¼Œå¹¶é€šè¿‡ï¼š
    ```python
    result_df.to_hdf("result.h5", key="data", mode="w")
    ```
    å†™å…¥åŒä¸€ç›®å½•ä¸‹çš„ `result.h5` æ–‡ä»¶ï¼Œåˆ—ä¸ºä¸€ä¸ªæˆ–å¤šä¸ª `float64` ç±»å‹çš„å› å­åˆ—.
  - åœ¨ Qlib å›æµ‹ä¸è”åˆå› å­å®éªŒçš„ YAML æ¨¡æ¿ä¸­ï¼Œè¿˜ä¼šé€šè¿‡ `StaticDataLoader/NestedDataLoader` è‡ªåŠ¨åŠ è½½è‹¥å¹²**é¢„è®¡ç®—å› å­è¡¨**ï¼ˆæ— éœ€åœ¨æ¯ä¸ª `factor.py` ä¸­é‡å¤è®¡ç®—ï¼‰ï¼Œä¾‹å¦‚ï¼š
    - å…¨å±€è‡ªç¼–ç å™¨å¼‚å¸¸æ£€æµ‹å› å­è¡¨ï¼š`ae_recon_error_10d`ï¼ˆ10 æ—¥é‡æ„è¯¯å·®ï¼‰ï¼Œè·¯å¾„ç±»ä¼¼ `.../factors/ae_recon_error_10d/result.h5`ï¼›
    - æ¯æ—¥æŒ‡æ ‡é¢„è®¡ç®—å› å­è¡¨ï¼š`daily_basic_factors/result.h5`ï¼ŒåŒ…å«ä¼°å€¼ã€å¸‚å€¼ã€æµåŠ¨æ€§ç­‰ `db_*` æ´¾ç”Ÿå› å­ï¼›
    - åç»­å¯èƒ½æ‰©å±•çš„èµ„é‡‘æµå› å­è¡¨ï¼š`capital_flow_daily/result.h5` ç­‰.
    è¿™äº›é¢„è®¡ç®—è¡¨åœ¨ Qlib ä¾§ä½œä¸ºé¢å¤–ç‰¹å¾è‡ªåŠ¨æ‹¼æ¥åˆ°æ¨¡å‹è¾“å…¥ä¸­ï¼Œç”¨äºè”åˆå› å­/ç­–ç•¥æ¼”è¿›ï¼›ä½ åœ¨å•ä¸€ `factor.py` ä¸­åªéœ€ä¸“æ³¨äºåŸºäº `daily_pv.h5` çš„æœ¬åœ°å› å­å®ç°ï¼Œä¸å¿…åœ¨è„šæœ¬é‡Œé‡å¤å®ç° AE/daily_basic/èµ„é‡‘æµæ•´è¡¨è®¡ç®—é€»è¾‘.

qlib_factor_strategy: |-
  Ensure that for every step of data processing, the data format (including indexes) is clearly explained through comments.
  Each transformation or calculation should be accompanied by a detailed description of how the data is structured, especially focusing on key aspects like whether the data has multi-level indexing, how to access specific columns or index levels, and any operations that affect the data shape (e.g., `reset_index()`, `groupby()`, `merge()`).
  This step-by-step explanation will ensure clarity and accuracy in data handling. For example:
  Note: The examples below are for explanation only. In this project, you should preserve the MultiIndex(`datetime`, `instrument`) contract and avoid index-changing operations unless explicitly required.
  1. **Start with multi-level index**:  
    ```python
    # The initial DataFrame has a multi-level index with 'datetime' and 'instrument'.
    # To access the 'datetime' index, use df.index.get_level_values('datetime').
    datetime_values = df.index.get_level_values('datetime')
    ```
 
  2. **Reset the index if necessary**:  
    ```python
    # Resetting the index to move 'datetime' and 'instrument' from the index to columns.
    # This operation flattens the multi-index structure.
    df = df.reset_index()
    ```
 
  3. **Perform groupby operations**:  
    ```python
    # Grouping by 'datetime' and 'instrument' to aggregate the data.
    # After groupby, the result will maintain 'datetime' and 'instrument' as a multi-level index.
    df_grouped = df.groupby(['datetime', 'instrument']).sum()
    ```
 
  4. **Ensure consistent datetime formats**:  
    ```python
    # Before merging, ensure that the 'datetime' column in both DataFrames is of the same format.
    # Convert to datetime format if necessary.
    df['datetime'] = pd.to_datetime(df['datetime'])
    other_df['datetime'] = pd.to_datetime(other_df['datetime'])
    ```
 
  5. **Merge operations**:  
    ```python
    # When merging DataFrames, ensure you are merging on both 'datetime' and 'instrument'.
    # If these are part of the index, reset the index before merging.
    merged_df = pd.merge(df, other_df, on=['datetime', 'instrument'], how='inner')
    ```

qlib_factor_output_format: |-
  Your output should be a pandas dataframe similar to the following example information:
  <class 'pandas.core.frame.DataFrame'>
  MultiIndex: 40914 entries, (Timestamp('2020-01-02 00:00:00'), 'SH600000') to (Timestamp('2021-12-31 00:00:00'), 'SZ300059')
  Data columns (total 1 columns):
  #   Column            Non-Null Count  Dtype  
  ---  ------            --------------  -----  
  0   your factor name  40914 non-null  float64
  dtypes: float64(1)
  memory usage: <ignore>
  Notice: The non-null count is OK to be different to the total number of entries since some instruments may not have the factor value on some days.
  One possible format of `result.h5` may be like following:
  datetime    instrument
  2020-01-02  SZ000001     -0.001796
              SZ000166      0.005780
              SZ000686      0.004228
              SZ000712      0.001298
              SZ000728      0.005330
                              ...
  2021-12-31  SZ000750      0.000000
              SZ000776      0.002459

qlib_factor_simulator: |-
  The factors will be sent into Qlib to train a model to predict the next several days return based on the factor values of the previous days. 
  Qlib is an AI-oriented quantitative investment platform that aims to realize the potential, empower research, and create value using AI technologies in quantitative investment, from exploring ideas to implementing productions. Qlib supports diverse machine learning modeling paradigms. including supervised learning, market dynamics modeling, and RL.
  User will use Qlib to automatically do the following things:
  1. generate a new factor table based on the factor values.
  2. train a model like LightGBM, CatBoost, LSTM or simple PyTorch model to predict the next several days return based on the factor values.
  3. build a portfolio based on the predicted return based on a strategy.
  4. evaluate the portfolio's performance including the return, sharpe ratio, max drawdown, and so on.

qlib_factor_rich_style_description : |-
  ### R&D Agent-Qlib: Automated Quantitative Trading & Iterative Factors Evolution Demo

  #### [Overview](#_summary)

  The demo showcases the iterative process of hypothesis generation, knowledge construction, and decision-making. It highlights how financial factors evolve through continuous feedback and refinement.

  #### [Automated R&D](#_rdloops)

  - **[R (Research)](#_research)**
    - Iterative development of ideas and hypotheses.
    - Continuous learning and knowledge construction.

  - **[D (Development)](#_development)**
    - Progressive implementation and code generation of factors.
    - Automated testing and validation of financial factors.

  #### [Objective](#_summary)

  To demonstrate the dynamic evolution of financial factors through the Qlib platform, emphasizing how each iteration enhances the accuracy and reliability of the resulting financial factors.

qlib_factor_from_report_rich_style_description : |-
  ### R&D Agent-Qlib: Automated Quantitative Trading & Factor Extraction from Financial Reports Demo

  #### [Overview](#_summary)

  This demo showcases the process of extracting factors from financial research reports, implementing these factors, and analyzing their performance through Qlib backtest, continually expanding and refining the factor library.

  #### [Automated R&D](#_rdloops)

  - **[R (Research)](#_research)**
    - Iterative development of ideas and hypotheses from financial reports.
    - Continuous learning and knowledge construction.

  - **[D (Development)](#_development)**
    - Progressive factor extraction and code generation.
    - Automated implementation and testing of financial factors.

  #### [Objective](#_summary)

  <table border="1" style="width:100%; border-collapse: collapse;">
    <tr>
      <td>ğŸ’¡ <strong>Innovation </strong></td>
      <td>Tool to quickly extract and test factors from research reports.</td>
    </tr>
    <tr>
      <td>âš¡ <strong>Efficiency </strong></td>
      <td>Rapid identification of valuable factors from numerous reports.</td>
    </tr>
    <tr>
      <td>ğŸ—ƒï¸ <strong>Outputs </strong></td>
      <td>Expand and refine the factor library to support further research.</td>
    </tr>
  </table>

qlib_factor_experiment_setting: |-
  | Dataset ğŸ“Š | Model ğŸ¤–    | Factors ğŸŒŸ       | Data Split  ğŸ§®                                   |
  |---------|----------|---------------|-------------------------------------------------|
  | AIstock A-share (non-ST, non-delisted)  | GRU_TimeSeries_Model | Alpha158 Plus + AIstock factors | Train: 2016-01-01 to 2018-12-31 <br> Valid: 2019-01-01 to 2020-12-31 <br> Test &nbsp;: 2021-01-01 to 2025-12-31 |
  
  #### è®¡ç®—èµ„æºä¸è®­ç»ƒè´Ÿè½½å»ºè®®ï¼ˆè¯·ä¼˜å…ˆæ»¡è¶³ä»¥ä¸‹è¦æ±‚ï¼Œä»¥å……åˆ†åˆ©ç”¨æœ¬æœº 12 æ ¸ 24 çº¿ç¨‹ + GPUï¼‰
  - **è®­ç»ƒè½®æ•°ä¸ batch å¤§å°**ï¼š
    - å¯¹äºä¸»è¦å®éªŒï¼Œè¯·é¿å…ä½¿ç”¨è¿‡å°é…ç½®ï¼ˆå¦‚ `n_epochs < 100`ã€`batch_size < 256`ï¼‰ã€‚
    - æ¨èé…ç½®èŒƒå›´ï¼š`n_epochs` åœ¨ `200~300`ï¼›`batch_size` ä»¥ `512` ä¸ºä¼˜å…ˆï¼ˆå¦‚æ˜¾å­˜ä¸è¶³å¯é™åˆ° `256`ï¼‰ã€‚
  - **å¹¶è¡Œåº¦è®¾ç½®ï¼ˆCPUï¼‰**ï¼š
    - å¯¹æ”¯æŒ `n_jobs` çš„æ¨¡å‹æˆ–æ•°æ®å¤„ç†ç»„ä»¶ï¼Œä¼˜å…ˆè®¾ç½®ä¸º `n_jobs: 12`ï¼ˆæ¥è¿‘ç‰©ç†æ ¸å¿ƒæ•°ï¼‰ã€‚
    - å¦‚ YAML ä¸­å­˜åœ¨ `workers` / `num_workers` / `processes` ç­‰å­—æ®µï¼Œå¯è®¾ç½®åœ¨ `8~12` ä¹‹é—´ï¼Œé¿å…è¿œé«˜äº CPU æ ¸å¿ƒæ•°ã€‚
  - **GPU ä½¿ç”¨**ï¼š
    - å¯¹åŸºäº PyTorch çš„æ—¶åºæ¨¡å‹ï¼ˆå¦‚ `GRU_TimeSeries_Model`ï¼‰ï¼Œå¿…é¡»ä¿è¯ `use_GPU: True`ï¼Œ`device: "cuda:0"`ï¼Œç¦æ­¢éšæ„æ”¹æˆ `cpu`ã€‚
  - **é“¾è·¯ç¨³å®šä¼˜å…ˆ**ï¼š
    - åœ¨åŠ å¤§è®­ç»ƒè´Ÿè½½å‰ï¼Œå…ˆç”¨è¾ƒå°å¾ªç¯ï¼ˆå¦‚ `--loop-n 1`ï¼‰ç¡®è®¤æ•´æ¡å› å­ä¸ Qlib è®­ç»ƒé“¾è·¯å®Œå…¨æ‰“é€šï¼š
      - ä½¿ç”¨ snapshot ä¸­å®é™…å­˜åœ¨ä¸”å¯ç”¨çš„è‚¡ç¥¨æ± ï¼ˆé€šå¸¸ä¸º `instruments: all`ï¼‰ã€‚
      - æ‰€æœ‰å› å­èƒ½åœ¨ `daily_pv.h5` ä¸ŠæˆåŠŸè®¡ç®—å¹¶ç”Ÿæˆ `result.h5`ã€‚
  - åªæœ‰åœ¨æ•´æ¡æµæ°´çº¿ä¸å†å‡ºç° `$close` / è‚¡ç¥¨æ± ä¸å­˜åœ¨ç­‰åŸºç¡€æŠ¥é”™åï¼Œæ‰é€æ­¥å¢åŠ  `n_epochs`ã€`batch_size` ä¸å¹¶è¡Œåº¦ã€‚
  
  #### è‚¡ç¥¨æ± ç­›é€‰ä¸æ¯æ—¥æŒ‡æ ‡å› å­çš„ä¼˜å…ˆä½¿ç”¨åŸåˆ™
  - åœ¨å› å­ä¸ç­–ç•¥æ¼”è¿›è¿‡ç¨‹ä¸­ï¼Œ**ä¼˜å…ˆä½¿ç”¨é¢„è®¡ç®—çš„ daily_basic å› å­è¡¨ï¼ˆä¼°å€¼ã€å¸‚å€¼ã€æµåŠ¨æ€§ç­‰ï¼‰åšç¨³å¥åŒ–ä¸é£é™©æ§åˆ¶**ï¼Œå†åœ¨ç›¸å¯¹â€œå¯äº¤æ˜“/å¯è§£é‡Šâ€çš„æ ·æœ¬ä¸Šè¿›è¡Œå¤šå› å­å»ºæ¨¡ä¸é€‰è‚¡ï¼š
    - ä¼˜å…ˆç”¨äºï¼šæš´éœ²æ§åˆ¶ï¼ˆè§„æ¨¡/æµåŠ¨æ€§ï¼‰ã€winsorize/clipã€åˆ†å±‚/åˆ†ç»„ä¸­æ€§åŒ–ã€ä»¥åŠå¯¹æç«¯å°¾éƒ¨æ ·æœ¬çš„æƒ©ç½šï¼ˆè¿‡æ»¤åº”ä½œä¸ºæœ€åæ‰‹æ®µï¼‰ï¼›
    - åœ¨åŠ å…¥æ–°å› å­å‰ï¼Œå…ˆç¡®ä¿åŸºç¡€å› å­é›†åœ¨ IC ä¸å›æµ‹ç¨³å®šæ€§ä¸Šä¸å†å‡ºç°ç³»ç»Ÿæ€§å´©åï¼ˆä¾‹å¦‚å…¨ NaN æˆ–æ˜¾è‘—è´Ÿæ”¶ç›Šï¼‰ã€‚
  
  #### ç­–ç•¥æ¼”è¿›ä¼˜å…ˆçº§ï¼ˆå½“ IC è¿ç»­ä¸º NaN æˆ–æ”¶ç›Šæ˜¾è‘—ä¸ºè´Ÿæ—¶ï¼‰
  - è‹¥æœ€è¿‘è‹¥å¹²è½®å®éªŒä¸­ï¼Œ**æ¨ªæˆªé¢ IC å¤§å¤šä¸º NaN/æ¥è¿‘ 0ï¼Œä¸”ç»„åˆå¹´åŒ–æ”¶ç›Šæ˜æ˜¾ä¸ºè´Ÿã€æœ€å¤§å›æ’¤è¿‡å¤§**ï¼Œè¯·ä¼˜å…ˆæ’æŸ¥å¹¶æ¼”è¿›ä»¥ä¸‹æ–¹å‘ï¼Œè€Œä¸æ˜¯ç›²ç›®æ›´æ¢æ›´å¤æ‚çš„æ—¶é—´åºåˆ—ç»“æ„ï¼š
    1. **å…ˆä¿®å› å­ä¸æ ‡ç­¾ï¼ˆä¿¡å·è´¨é‡ä¼˜å…ˆï¼‰**ï¼š
       - æ£€æŸ¥å› å­æ˜¯å¦è¿‘ä¼¼å¸¸æ•°ã€æ˜¯å¦è¿‡åº¦ç¨€ç–ã€æ˜¯å¦å› å¯¹é½/merge/dropna å¯¼è‡´æœ‰æ•ˆæ ·æœ¬å´©å¡Œï¼›
       - æ£€æŸ¥å¹¶ä¼˜åŒ–æ ‡ç­¾ï¼šåˆç†é€‰æ‹©é¢„æµ‹çª—å£ï¼ˆä¾‹å¦‚ 1D/5D/10D æ”¶ç›Šï¼‰ï¼Œå¹¶æ˜ç¡®æ˜¯ç»å¯¹æ”¶ç›Šè¿˜æ˜¯è¶…é¢æ”¶ç›Šï¼Œç¡®ä¿è¯„ä¼°æŒ‡æ ‡ä¸æ ‡ç­¾å£å¾„ä¸€è‡´ã€‚
    2. **ç”¨åŸºç¡€å› å­åšç¨³å¥åŒ–ä¸é£é™©ç”¨é€”**ï¼š
       - `daily_basic`ï¼ˆä¼°å€¼/å¸‚å€¼/æµåŠ¨æ€§ï¼‰ä¼˜å…ˆç”¨äºæš´éœ²æ§åˆ¶ä¸ç¨³å®šæ€§çº¦æŸï¼ˆå¿…è¦æ—¶æ‰åšè¿‡æ»¤ï¼‰ï¼›
       - `ae_recon_error_10d` æ›´é€‚åˆä½œä¸ºå¼‚å¸¸æ£€æµ‹/é£é™©å› å­å‚ä¸æƒ©ç½šæˆ–è¿‡æ»¤ï¼Œè€Œä¸æ˜¯å•ç‹¬æ‰¿æ‹…ä¸»è¦é€‰è‚¡ä¿¡å·ã€‚
    3. **æ§åˆ¶å› å­æ•°é‡ä¸ç›¸å…³æ€§ï¼Œå…ˆè·‘ç¨³ Tabular åŸºçº¿**ï¼š
       - é¿å…å¤§é‡é«˜åº¦å…±çº¿æˆ–æåº¦ç¨€ç–çš„æ–°å› å­ï¼›
       - å…ˆåœ¨ LightGBM / CatBoost / ç®€å• MLP ç­‰ Tabular åŸºçº¿ä¸‹éªŒè¯ IC ä¸å†ä¸º NaN ä¸”æ”¶ç›Šä¸å†ç³»ç»Ÿæ€§ä¸ºè´Ÿï¼Œå†è€ƒè™‘å¼•å…¥æ›´å¤æ‚çš„æ—¶åºç»“æ„ã€‚

qlib_model_background: |-
  The model is a machine learning or deep learning structure used in quantitative investment to predict the returns and risks of a portfolio or a single asset. Models are employed by investors to generate forecasts based on historical data and identified factors, which are central to many quantitative investment strategies.
  Each model takes the factors as input and predicts the future returns. Usually, the bigger the model is, the better the performance would be.
  The model is defined in the following parts:
  1. Name: The name of the model.
  2. Description: The description of the model.
  3. Architecture: The detailed architecture of the model, such as neural network layers or tree structures.
  4. Hyperparameters: The hyperparameters used in the model.
  5. Training_hyperparameters: The hyperparameters used during the training process.
  6. ModelType: The type of the model, "Tabular" for tabular model and "TimeSeries" for time series model.
  The model should provide clear and detailed documentation of its architecture and hyperparameters. One model should statically define one output with a fixed architecture and hyperparameters.

  {% if runtime_environment is not none %}
  ====== Runtime Environment ======
  You have following environment to run the code:
  {{ runtime_environment }}
  {% endif %}

qlib_model_interface: |-
  Your python code should follow the interface to better interact with the user's system.
  You code should contain several parts:
  1. The import part: import the necessary libraries.
  2. A class which is a sub-class of pytorch.nn.Module. This class should should have a init function and a forward function which inputs a tensor and outputs a tensor.
  3. Set a variable called "model_cls" to the class you defined.

  The user will save your code into a python file called "model.py". Then the user imports model_cls in file "model.py" after setting the cwd into the directory:
  ```python
  from model import model_cls
  ```
  So your python code should follow the pattern:
  ```python
  class XXXModel(torch.nn.Module):
      ...
  model_cls = XXXModel
  ```

  The model can be configured as either "Tabular" for tabular models or "TimeSeries" for time series models. For a tabular model, the input shape is (batch_size, num_features), while for a time series model, the input shape is (batch_size, num_timesteps, num_features). In both cases, the output shape of the model should be (batch_size, 1).
  `num_features` will be directly set for the model based on the input data shape.
  User will initialize the tabular model with the following code:
  ```python
  model = model_cls(num_features=num_features)
  ```
  User will initialize the time series model with the following code:
  ```python
  model = model_cls(num_features=num_features, num_timesteps=num_timesteps)
  ```
  No other parameters will be passed to the model so give other parameters a default value or just make them static.

  Don't write any try-except block in your python code. The user will catch the exception message and provide the feedback to you. Also, don't write main function in your python code. The user will call the forward method in the model_cls to get the output tensor.

  Please notice that your model should only use current features as input. The user will provide the input tensor to the model's forward function.


qlib_model_output_format: |-
  Your output should be a tensor with shape (batch_size, 1). 
  The output tensor should be saved in a file named "output.pth" in the same directory as your python file.
  The user will evaluate the shape of the output tensor so the tensor read from "output.pth" should be 8 numbers.

qlib_model_simulator: |-
  The models will be sent into Qlib to train and evaluate their performance in predicting future returns. Hypothesis is improved upon checking the feedback on the results. 
  Qlib is an AI-oriented quantitative investment platform that aims to realize the potential, empower research, and create value using AI technologies in quantitative investment, from exploring ideas to implementing productions. Qlib supports diverse machine learning modeling paradigms, including supervised learning, market dynamics modeling, and reinforcement learning (RL).
  User will use Qlib to automatically perform the following tasks:
  1. Generate a baseline factor table.
  2. Train the model defined in your class Net to predict the next several days' returns based on the factor values.
  3. Build a portfolio based on the predicted returns using a specific strategy.
  4. Evaluate the portfolio's performance, including metrics such as return, IC, max drawdown, and others.
  5. Iterate on growing the hypothesis to enable model improvements based on performance evaluations and feedback.

qlib_model_rich_style_description: |-
  ### Qlib Model Evolving Automatic R&D Demo
  
  #### [Overview](#_summary)
  
  The demo showcases the iterative process of hypothesis generation, knowledge construction, and decision-making in model construction in quantitative finance. It highlights how models evolve through continuous feedback and refinement.
  
  #### [Automated R&D](#_rdloops)
  
  - **[R (Research)](#_research)**
    - Iteration of ideas and hypotheses.
    - Continuous learning and knowledge construction.
  
  - **[D (Development)](#_development)**
    - Evolving code generation and model refinement.
    - Automated implementation and testing of models.
  
  #### [Objective](#_summary)
  
  To demonstrate the dynamic evolution of models through the Qlib platform, emphasizing how each iteration enhances the accuracy and reliability of the resulting models. 

qlib_model_experiment_setting: |-
  | Dataset ğŸ“Š | Model ğŸ¤–    | Factors ğŸŒŸ       | Data Split  ğŸ§®                                   |
  |---------|----------|---------------|-------------------------------------------------|
  | AIstock A-share (non-ST, non-delisted)  | ä¾‹å¦‚ GRU_TimeSeries_Modelï¼ˆä¹Ÿå¯æ›¿æ¢ä¸º LGB/MLP/Transformer ç­‰å…¶å®ƒæ¨¡å‹ï¼‰ | 20 factors (Alpha158)  | Train: 2016-01-01 to 2018-12-31 <br> Valid: 2019-01-01 to 2020-12-31 <br> Test &nbsp;: 2021-01-01 to 2025-12-31 |

transformer_volume_price_strategy: |-
  æœ¬æ®µè½æè¿°çš„æ˜¯ä¸€å¥— **ç¤ºä¾‹å‹** ç­–ç•¥è®¾æƒ³ï¼Œä¸»è¦ç”¨äºå±•ç¤ºå¦‚ä½•å°†é‡ä»·ç‰¹å¾ä¸æ—¶é—´åºåˆ—æ¨¡å‹ï¼ˆä¾‹å¦‚ Transformerï¼‰ç»“åˆï¼Œç”¨äºå¤šè‚¡ç¥¨ç»„åˆçš„ç ”ç©¶ä¸å›æµ‹ã€‚

  éœ€è¦ç‰¹åˆ«å¼ºè°ƒçš„æ˜¯ï¼š
  - è¿™é‡Œæåˆ°çš„æ¨¡å‹ç±»å‹ï¼ˆå¦‚ TransformerEncoderï¼‰ã€è°ƒä»“è§„åˆ™ã€æŒä»“è‚¡ç¥¨æ•°é‡ï¼ˆä¾‹å¦‚ 30 åªï¼‰ã€æ­¢ç›ˆæ­¢æŸé˜ˆå€¼ç­‰ï¼Œ**ä»…ä½œä¸ºç¤ºä¾‹/çµæ„Ÿæ¥æº**ï¼›
  - å®ƒä»¬ **ä¸å¯¹å½“å‰ä»»åŠ¡æˆ–ä»»ä½•å…·ä½“å®éªŒæ„æˆç¡¬æ€§çº¦æŸ**ï¼Œä½ åœ¨å®é™…ç ”å‘ä¸­å¯ä»¥è‡ªç”±é€‰æ‹© LightGBMã€CatBoostã€MLPã€GRUã€Transformer ç­‰ä»»æ„æ¨¡å‹ï¼Œä¹Ÿå¯ä»¥è‡ªç”±è®¾è®¡é€‰è‚¡æ•°é‡ä¸é£æ§è§„åˆ™ï¼›
  - æœ¬é¡¹ç›®çš„å…¶å®ƒæç¤ºè¯ï¼ˆå› å­/æ¨¡å‹/å›æµ‹é…ç½®ï¼‰åŒæ ·ä¸å¼ºåˆ¶ç»‘å®šæŸä¸€ç§æ¨¡å‹æˆ–å…·ä½“ç­–ç•¥å½¢æ€ï¼Œè€Œæ˜¯ä»¥â€œæ•°æ®æ ¼å¼ä¸ç´¢å¼• contract æ­£ç¡®â€ä¸ºå”¯ä¸€åˆšæ€§çº¦æŸã€‚

  ç¤ºä¾‹æ€æƒ³ï¼ˆå¯é€‰å‚è€ƒï¼‰ï¼š
  - å…³æ³¨æœªæ¥è‹¥å¹²äº¤æ˜“æ—¥ï¼ˆä¾‹å¦‚ 1/5/10/30 æ—¥ï¼‰çš„æ”¶ç›Šè¡¨ç°ï¼Œè€Œä¸æ˜¯è¶…é•¿å‘¨æœŸæŒæœ‰ï¼›
  - åœ¨æ”¶ç›Šä¸é£é™©ä¹‹é—´è®¾å®šåˆç†çš„ç›®æ ‡åŒºé—´ï¼ˆä¾‹å¦‚æœŸæœ›å¹´åŒ–æ”¶ç›Šã€æœ€å¤§å›æ’¤ã€å•ç¬”é£é™©æ•å£ä¸Šé™ç­‰ï¼‰ï¼Œå¹¶åœ¨å› å­è®¾è®¡ã€æ¨¡å‹ç»“æ„ä»¥åŠè°ƒä»“è§„åˆ™ä¸­ç»¼åˆè€ƒè™‘ï¼›
  - ä»¥é‡ä»·ç‰¹å¾ä¸ºä¸€ä¸ªé‡è¦ç»´åº¦ï¼ŒåŒæ—¶å…è®¸ç»“åˆä¼°å€¼ã€å¸‚å€¼ã€AE å¼‚å¸¸åº¦ã€å®è§‚æƒ…ç»ªç­‰å¤šæ–¹é¢ä¿¡å·ï¼Œæ„å»ºå¤šå› å­ä¸å¤šå‘¨æœŸçš„ç­–ç•¥æ¡†æ¶ï¼›
  - å¯¹äºæ—¶é—´åºåˆ—å»ºæ¨¡ï¼Œå¯ä»¥é€‰æ‹© Transformerã€GRUã€TCN ç­‰ï¼Œä¹Ÿå¯ä»¥å›åˆ°ç®€å•çš„æˆªé¢æ¨¡å‹ï¼ˆå¦‚ LGB/MLPï¼‰å¹¶é…åˆæ»šåŠ¨çª—å£ç‰¹å¾æ„é€ å®Œæˆç­–ç•¥è®¾è®¡ã€‚

  æ€»ä¹‹ï¼Œæœ¬æ®µä»…ä½œä¸ºâ€œå¦‚ä½•æ„æ€ä¸€å¥—è¾ƒä¸ºå®Œæ•´çš„é‡ä»·+æ—¶åºç­–ç•¥â€çš„ **ç¤ºä¾‹æ–‡æ¡£**ã€‚åœ¨å®é™…è‡ªåŠ¨ç ”å‘ä¸æ¼”è¿›è¿‡ç¨‹ä¸­ï¼Œä½ å®Œå…¨å¯ä»¥æ ¹æ®å®éªŒç»“æœä¸ä»»åŠ¡éœ€æ±‚ï¼Œè‡ªä¸»å†³å®šä½¿ç”¨çš„æ¨¡å‹ç±»å‹ã€é€‰è‚¡æ•°é‡ã€æŒä»“å‘¨æœŸä»¥åŠæ˜¯å¦é‡‡ç”¨æ­¢ç›ˆ/æ­¢æŸæœºåˆ¶ã€‚