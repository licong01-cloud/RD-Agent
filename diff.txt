diff --git a/rdagent/app/results_api_server.py b/rdagent/app/results_api_server.py
index 5f162039..f794c05e 100644
--- a/rdagent/app/results_api_server.py
+++ b/rdagent/app/results_api_server.py
@@ -7,6 +7,8 @@ import zipfile
 import io
 import os
 from datetime import datetime, timezone
+import sqlite3
+import re
 
 from fastapi import FastAPI, HTTPException, Query
 from fastapi.middleware.cors import CORSMiddleware
@@ -38,10 +40,441 @@ def create_app() -> FastAPI:
 
     reg = get_registry()
 
+    def _db_path() -> Path:
+        return Path(reg.config.db_path)
+
+    def _repo_root() -> Path:
+        return _db_path().parent.parent
+
+    def _bundles_root() -> Path:
+        return _repo_root() / "RDagentDB" / "production_bundles"
+
+    def _log_root() -> Path:
+        return _repo_root() / "log"
+
+    def _workspace_root() -> Path:
+        return _repo_root() / "git_ignore_folder" / "RD-Agent_workspace"
+
+    def _open_registry_db() -> sqlite3.Connection:
+        conn = sqlite3.connect(str(_db_path()))
+        conn.row_factory = sqlite3.Row
+        return conn
+
+    _hex32_re = re.compile(r"\b[0-9a-f]{32}\b", flags=re.IGNORECASE)
+    _ws_re = re.compile(r"RD-Agent_workspace/([0-9a-f]{32})", flags=re.IGNORECASE)
+
+    def _find_task_run_id_in_registry(*, task_id: str) -> str | None:
+        tid = str(task_id).strip()
+        if not tid:
+            return None
+        with _open_registry_db() as conn:
+            row = conn.execute(
+                """
+                SELECT task_run_id
+                FROM task_runs
+                WHERE log_trace_path LIKE ? OR log_trace_path LIKE ?
+                ORDER BY updated_at_utc DESC
+                LIMIT 1
+                """,
+                (f"%/log/{tid}%", f"%\\log\\{tid}%"),
+            ).fetchone()
+            if row is None:
+                return None
+            v = row["task_run_id"]
+            return str(v).lower() if v else None
+
+    def _list_workspace_ids_from_registry(*, task_run_id: str) -> list[str]:
+        trid = str(task_run_id).strip().lower()
+        if not trid:
+            return []
+        out: list[str] = []
+        with _open_registry_db() as conn:
+            cur = conn.execute(
+                """
+                SELECT workspace_id
+                FROM loops
+                WHERE task_run_id = ? AND workspace_id IS NOT NULL AND workspace_id != ''
+                ORDER BY loop_id DESC
+                LIMIT 10
+                """,
+                (trid,),
+            )
+            rows = cur.fetchall() or []
+            for r in rows:
+                ws = (r["workspace_id"] if isinstance(r, sqlite3.Row) else r[0])
+                if ws:
+                    out.append(str(ws).lower())
+        seen = set()
+        uniq: list[str] = []
+        for ws in out:
+            if ws in seen:
+                continue
+            seen.add(ws)
+            uniq.append(ws)
+        return uniq
+
+    def _iter_recent_log_tasks(*, limit: int) -> list[dict[str, Any]]:
+        root = _log_root()
+        if not root.exists():
+            return []
+
+        items: list[tuple[float, str]] = []
+        for entry in root.iterdir():
+            if not entry.is_dir():
+                continue
+            try:
+                mtime = entry.stat().st_mtime
+            except OSError:
+                continue
+            items.append((mtime, entry.name))
+
+        items.sort(key=lambda x: x[0], reverse=True)
+        out: list[dict[str, Any]] = []
+        for mtime, name in items[: int(limit)]:
+            out.append({"task_id": name, "updated_at_utc": datetime.fromtimestamp(mtime, tz=timezone.utc).isoformat()})
+        return out
+
+    def _extract_task_run_id_from_log_dir(*, task_id: str) -> str | None:
+        log_dir = _log_root() / str(task_id)
+        if not log_dir.exists() or not log_dir.is_dir():
+            return None
+
+        candidates: set[str] = set()
+        max_files = 200
+        max_read_bytes = 256 * 1024
+        scanned = 0
+        for p in log_dir.rglob("*"):
+            if not p.is_file():
+                continue
+            scanned += 1
+            if scanned > max_files:
+                break
+            # 鍙鍓?2MB锛岄伩鍏嶆壂鐖嗗唴瀛?+            try:
+                bs = p.read_bytes()[:max_read_bytes]
+            except OSError:
+                continue
+
+            try:
+                text = bs.decode("utf-8", errors="ignore")
+            except Exception:
+                continue
+            for m in _hex32_re.finditer(text):
+                candidates.add(m.group(0).lower())
+
+        if not candidates:
+            return None
+
+        with _open_registry_db() as conn:
+            for h in candidates:
+                row = conn.execute(
+                    "SELECT 1 FROM loops WHERE task_run_id = ? LIMIT 1",
+                    (h,),
+                ).fetchone()
+                if row is not None:
+                    return h
+        return None
+
+    def _extract_workspace_ids_from_log_dir(*, task_id: str) -> list[str]:
+        log_dir = _log_root() / str(task_id)
+        if not log_dir.exists() or not log_dir.is_dir():
+            return []
+
+        found: set[str] = set()
+        max_files = 200
+        max_read_bytes = 256 * 1024
+        scanned = 0
+        for p in log_dir.rglob("*"):
+            if not p.is_file():
+                continue
+            scanned += 1
+            if scanned > max_files:
+                break
+            try:
+                bs = p.read_bytes()[:max_read_bytes]
+            except OSError:
+                continue
+            try:
+                text = bs.decode("utf-8", errors="ignore")
+            except Exception:
+                continue
+            for m in _ws_re.finditer(text):
+                found.add(m.group(1).lower())
+
+        # 杩囨护鎺変笉瀛樺湪鐨?workspace
+        ws_root = _workspace_root()
+        out: list[str] = []
+        for ws in sorted(found):
+            if (ws_root / ws).exists():
+                out.append(ws)
+        return out
+
+    def _get_latest_tasks(*, limit: int) -> list[dict[str, Any]]:
+        # AIstock 鐨?task_id 鏉ヨ嚜 log/<鏃堕棿鎴崇洰褰曞悕>锛岃繖閲岀洿鎺ヤ互 log 涓烘潈濞佹潵婧?+        return _iter_recent_log_tasks(limit=int(limit))
+
+    def _resolve_bundle_for_task(*, task_id: str) -> dict[str, Any]:
+        tid = str(task_id).strip()
+        if not tid:
+            raise HTTPException(status_code=400, detail="task_id 涓虹┖")
+
+        # 鍏煎涓ょ杈撳叆锛?+        # - 32浣?hex锛氳涓?task_run_id
+        # - 鏃堕棿鎴崇洰褰曞悕锛氬厛浠?log 涓В鏋愬嚭 task_run_id
+        task_run_id = tid.lower()
+        if not _hex32_re.fullmatch(task_run_id):
+            parsed = _find_task_run_id_in_registry(task_id=tid)
+            if not parsed:
+                parsed = _extract_task_run_id_from_log_dir(task_id=tid)
+            if not parsed:
+                # 鍏滃簳锛氶儴鍒?RD-Agent 鐗堟湰/杩愯鏂瑰紡鍙兘涓嶄細鎶?task_run_id 鍐欏叆 log_trace_path锛?+                # 鎴栬€?log 閲岄毦浠ユ娊鍙?task_run_id銆?+                # 鍙鑳戒粠 log 涓娊鍙栧嚭 workspace_id锛屽氨鍏佽鏋勫缓涓€涓熀浜?workspace 鐨?task 瑙嗗浘锛?+                # 浠ユ敮鎸?AIstock 鍚屾涓庤祫浜т笅杞姐€?+                ws_ids = _extract_workspace_ids_from_log_dir(task_id=tid)
+                if ws_ids:
+                    wd = _workspace_root() / ws_ids[0]
+                    return {
+                        "task_id": tid,
+                        "task_run_id": "",
+                        "loop_id": 0,
+                        "asset_bundle_id": "",
+                        "bundle_dir": None,
+                        "bundle_manifest": None,
+                        "workspace_id": ws_ids[0],
+                        "workspace_dir": wd if wd.exists() else None,
+                    }
+                raise HTTPException(status_code=404, detail=f"task_id not found in logs/registry: {tid}")
+            task_run_id = parsed
+
+        with _open_registry_db() as conn:
+            row = conn.execute(
+                """
+                SELECT task_run_id, loop_id, asset_bundle_id
+                FROM loops
+                WHERE task_run_id = ?
+                ORDER BY loop_id DESC
+                LIMIT 1
+                """,
+                (task_run_id,),
+            ).fetchone()
+            if row is None:
+                raise HTTPException(status_code=404, detail=f"task_run_id not found in registry: {task_run_id}")
+
+            asset_bundle_id = row["asset_bundle_id"]
+            loop_id = int(row["loop_id"])
+
+            bundle_dir: Path | None = None
+            bundle_manifest: dict[str, Any] | None = None
+            primary_workspace_id: str | None = None
+            workspace_dir: Path | None = None
+
+            if asset_bundle_id:
+                bd = _bundles_root() / str(asset_bundle_id)
+                if bd.exists():
+                    bm = _load_json(bd / "manifest.json")
+                    if isinstance(bm, dict):
+                        bundle_dir = bd
+                        bundle_manifest = bm
+                        pw = (
+                            bm.get("primary_workspace_id")
+                            or bm.get("primary_workspace")
+                            or bm.get("workspace_id")
+                        )
+                        if pw:
+                            primary_workspace_id = str(pw)
+                            wd = bd / "workspaces" / str(pw)
+                            if wd.exists():
+                                workspace_dir = wd
+
+            # 鑻?bundle 鏈氨缁紙asset_bundle_id 涓虹┖鎴栫洰褰曠己澶憋級锛屽洖閫€鍒?log 涓娊鍙栫殑 workspace
+            if workspace_dir is None:
+                ws_ids = _list_workspace_ids_from_registry(task_run_id=task_run_id)
+                if not ws_ids:
+                    ws_ids = _extract_workspace_ids_from_log_dir(task_id=tid)
+                if ws_ids:
+                    primary_workspace_id = ws_ids[0]
+                    wd = _workspace_root() / ws_ids[0]
+                    if wd.exists():
+                        workspace_dir = wd
+
+            return {
+                "task_id": tid,
+                "task_run_id": task_run_id,
+                "loop_id": loop_id,
+                "asset_bundle_id": str(asset_bundle_id) if asset_bundle_id else "",
+                "bundle_dir": bundle_dir,
+                "bundle_manifest": bundle_manifest,
+                "workspace_id": str(primary_workspace_id) if primary_workspace_id else "",
+                "workspace_dir": workspace_dir,
+            }
+
+    def _list_workspace_assets(*, workspace_dir: Path) -> list[dict[str, Any]]:
+        allow_ext = {
+            ".py",
+            ".yaml",
+            ".yml",
+            ".json",
+            ".csv",
+            ".pkl",
+            ".pt",
+            ".txt",
+            ".md",
+            ".png",
+        }
+        max_bytes = 200 * 1024 * 1024
+
+        out: list[dict[str, Any]] = []
+        for p in workspace_dir.iterdir():
+            if not p.is_file():
+                continue
+            suffix = p.suffix.lower()
+            if suffix not in allow_ext:
+                continue
+            try:
+                size = p.stat().st_size
+            except OSError:
+                continue
+            if size > max_bytes:
+                continue
+            out.append({"name": p.name, "size": int(size)})
+
+        out.sort(key=lambda x: (x["name"] != "factor_entry.py", x["name"]))
+        return out
+
+    def _pick_primary_assets(*, ws_id: str, files: list[dict[str, Any]]) -> dict[str, str]:
+        names = [f["name"] for f in files]
+
+        def rel(n: str) -> str:
+            return f"workspaces/{ws_id}/{n}"
+
+        factor = "factor_entry.py" if "factor_entry.py" in names else ""
+
+        model = ""
+        for cand in ("model.pkl", "model.pt", "model.pth"):
+            if cand in names:
+                model = cand
+                break
+
+        config = ""
+        for cand in ("conf_baseline.yaml", "conf_baseline.yml", "conf_baseline_factors_model.yaml", "conf_sota_factors_model.yaml"):
+            if cand in names:
+                config = cand
+                break
+        if not config:
+            for n in names:
+                if n.lower().endswith((".yaml", ".yml")):
+                    config = n
+                    break
+
+        return {
+            "factor_entry_relpath": rel(factor) if factor else "",
+            "model_weight_relpath": rel(model) if model else "",
+            "config_relpath": rel(config) if config else "",
+        }
+
+    def _build_task_manifest(task_id: str) -> dict[str, Any]:
+        info = _resolve_bundle_for_task(task_id=task_id)
+        ws_id = info["workspace_id"]
+
+        ws_dir = info.get("workspace_dir")
+        assets: list[dict[str, Any]] = []
+        primary_assets: dict[str, str] = {
+            "factor_entry_relpath": "",
+            "model_weight_relpath": "",
+            "config_relpath": "",
+        }
+
+        if ws_id and isinstance(ws_dir, Path) and ws_dir.exists():
+            files = _list_workspace_assets(workspace_dir=ws_dir)
+            assets = [{"relpath": f"workspaces/{ws_id}/{f['name']}", "size": f["size"]} for f in files]
+            primary_assets = _pick_primary_assets(ws_id=ws_id, files=files)
+
+        return {
+            "schema_version": 1,
+            "task_id": info["task_id"],
+            "task_run_id": info["task_run_id"],
+            "loop_id": info["loop_id"],
+            "asset_bundle_id": info["asset_bundle_id"],
+            "generated_at_utc": datetime.now(timezone.utc).isoformat(),
+            "primary_assets": primary_assets,
+            "assets": assets,
+            "source": {
+                "bundle_manifest": info.get("bundle_manifest")
+            },
+        }
+
     @app.get("/health")
     def health() -> dict[str, str]:
         return {"status": "ok"}
 
+    @app.get("/tasks/latest")
+    def tasks_latest(limit: int = 20) -> dict[str, Any]:
+        items = _get_latest_tasks(limit=int(limit))
+        return {"ok": True, "count": len(items), "tasks": items}
+
+    @app.get("/tasks/{task_id}/summary")
+    def task_summary(task_id: str) -> dict[str, Any]:
+        info = _resolve_bundle_for_task(task_id=task_id)
+        return {
+            "ok": True,
+            "task_id": info["task_id"],
+            "task_run_id": info["task_run_id"],
+            "loop_id": info["loop_id"],
+            "asset_bundle_id": info["asset_bundle_id"],
+            "workspace_id": info["workspace_id"],
+            "bundle_manifest": info.get("bundle_manifest"),
+        }
+
+    @app.get("/tasks/{task_id}")
+    def task_manifest(task_id: str) -> dict[str, Any]:
+        return _build_task_manifest(task_id)
+
+    @app.get("/tasks/{task_id}/assets")
+    def task_asset_download(task_id: str, relpath: str = Query(...)) -> StreamingResponse:
+        info = _resolve_bundle_for_task(task_id=task_id)
+        rp = str(relpath or "").strip().replace("\\", "/")
+        while rp.startswith("/"):
+            rp = rp[1:]
+        if not rp:
+            raise HTTPException(status_code=400, detail="relpath 涓虹┖")
+
+        # 浼樺厛浠?bundle_dir 涓嬪彇锛涘惁鍒欏洖閫€ workspace_dir
+        base_dir: Path | None = info.get("bundle_dir") or None
+        if base_dir is None:
+            ws_dir = info.get("workspace_dir")
+            if isinstance(ws_dir, Path):
+                base_dir = ws_dir
+
+        if base_dir is None:
+            raise HTTPException(status_code=404, detail="no bundle/workspace available for this task")
+
+        # 鍏煎 relpath = workspaces/<ws_id>/xxx
+        if rp.startswith("workspaces/"):
+            parts = rp.split("/", 2)
+            if len(parts) >= 3:
+                rp = parts[2]
+
+        target = (base_dir / rp).resolve()
+        if not str(target).startswith(str(base_dir.resolve())):
+            raise HTTPException(status_code=400, detail="invalid relpath")
+        if not target.exists() or not target.is_file():
+            raise HTTPException(status_code=404, detail=f"asset not found: {relpath}")
+
+        def iter_file():
+            with target.open("rb") as f:
+                while True:
+                    chunk = f.read(1024 * 1024)
+                    if not chunk:
+                        break
+                    yield chunk
+
+        return StreamingResponse(
+            iter_file(),
+            media_type="application/octet-stream",
+            headers={"Content-Disposition": f"attachment; filename={target.name}"},
+        )
+
     @app.get("/catalog/factors")
     def get_factor_catalog() -> Any:
         db_path = reg.config.db_path
