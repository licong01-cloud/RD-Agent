hypothesis_and_feedback: |-
  =========================================================
  {% for experiment, feedback in trace.hist %}
  # Trial {{ loop.index }}:
  ## Hypothesis
  {{ experiment.hypothesis }}
  ## Specific task:
  {% for task in experiment.sub_tasks %}
  {% if task is not none and task.get_task_brief_information is defined %}
  {{ task.get_task_brief_information() }}
  {% endif %}
  {% endfor %}
  ## Backtest Analysis and Feedback:
  {% if experiment.result is not none %}
  Backtest Result: {{ experiment.result.loc[["IC", "1day.excess_return_without_cost.annualized_return", "1day.excess_return_without_cost.max_drawdown"]] }}
  {% endif %}
  Observation: {{ feedback.observations }}
  Hypothesis Evaluation: {{ feedback.hypothesis_evaluation }}
  Decision (Whether the hypothesis was successful): {{ feedback.decision }}
  =========================================================
  {% endfor %}

last_hypothesis_and_feedback: |-
  ## Hypothesis
  {{ experiment.hypothesis }}
  ## Specific task:
  {% for task in experiment.sub_tasks %}
  {% if task is not none and task.get_task_brief_information is defined %}
  {{ task.get_task_brief_information() }}
  {% endif %}
  {% endfor %}
  ## Backtest Analysis and Feedback:
  {% if experiment.result is not none %}
  Backtest Result: {{ experiment.result.loc[["IC", "1day.excess_return_without_cost.annualized_return", "1day.excess_return_without_cost.max_drawdown"]] }}
  {% endif %}
  Training Log:
  Here, you need to focus on analyzing whether there are any issues with the training. If any problems are identified, you must correct them in the next iteration and clearly describe how the changes will be made in the hypothesis.
  {{ experiment.stdout }}
  Observation: {{ feedback.observations }}
  Evaluation: {{ feedback.hypothesis_evaluation }}
  Decision (Whether this experiment is SOTA): {{ feedback.decision }}
  New Hypothesis (Given in feedback stage, just for reference, and can be accepted or rejected in the next round): {{ feedback.new_hypothesis }}
  Reasoning (Justification for the new hypothesis): {{ feedback.reason }}

sota_hypothesis_and_feedback: |-
  ## Hypothesis
  {{ experiment.hypothesis }}
  ## Specific task:
  {% for task in experiment.sub_tasks %}
  {% if task is not none and task.get_task_brief_information is defined %}
  {{ task.get_task_brief_information() }}
  {% endif %}
  {% endfor %}
  ## Backtest Analysis and Feedback:
  {% if experiment.result is not none %}
  Backtest Result: {{ experiment.result.loc[["IC", "1day.excess_return_without_cost.annualized_return", "1day.excess_return_without_cost.max_drawdown"]] }}
  {% endif %}
  Training Log: {{ experiment.stdout }}
  Observation: {{ feedback.observations }}
  Evaluation: {{ feedback.hypothesis_evaluation }}
  Decision (Whether this experiment is SOTA): {{ feedback.decision }}

hypothesis_output_format: |-
  The output should follow JSON format. The schema is as follows:
  {
  "hypothesis": "An exact, testable, and innovative statement derived from previous experimental trace analysis. Avoid overly general ideas and ensure precision. The hypothesis should clearly specify the exact approach and expected improvement in performance in two or three sentences. **All natural-language content here must be written in concise professional Chinese.**",
  "reason": "Provide a clear, logical explanation for why this hypothesis was proposed, grounded in evidence (e.g., trace history, domain principles). Reason should be short with no more than two sentences. **All natural-language content here must be written in concise professional Chinese.**",
  }

factor_hypothesis_output_format: |-
  The output should follow JSON format. The schema is as follows:
  {
  "hypothesis": "The new hypothesis generated based on the information provided. Limit in two or three sentences. **All natural-language content here must be written in concise professional Chinese.**",
  "reason": "The reason why you generate this hypothesis. It should be comprehensive and logical. It should cover the other keys below and extend them. Limit in two or three sentences. **All natural-language content here must be written in concise professional Chinese.**",
  }

hypothesis_output_format_with_action: |-
  The output should follow JSON format. The schema is as follows:
  {
  "action": "If `hypothesis_specification` provides the action you need to take, please follow "hypothesis_specification" to choose the action. Otherwise, based on previous experimental results, suggest the action you believe is most appropriate at the moment. It should be one of [`factor`, `model`].",
  "hypothesis": "The new hypothesis generated based on the information provided,should be a string. **All natural-language content here must be written in concise professional Chinese.**",
  "reason": "The reason why you generate this hypothesis. It should be comprehensive and logical. It should cover the other keys below and extend them. Limit in two or three sentences. **All natural-language content here must be written in concise professional Chinese.**",
  }

qlib_quant_background: |-
  Quantitative investment is a data-driven approach to asset management that relies on mathematical models, statistical techniques, and computational methods to analyze financial markets and make investment decisions. Two essential components of this approach are factors and models.

  You are one of the most authoritative quantitative researchers at a top Wall Street hedge fund. I need your expertise to develop new factors and models that can enhance our investment returns. Based on the given context, I will ask for your assistance in designing and implementing either factors or a model.

  {% if runtime_environment is not none %}
  ====== Runtime Environment ======
  You have following environment to run the code:
  {{ runtime_environment }}
  {% endif %}

qlib_factor_background: |-
  The factor is a characteristic or variable used in quant investment that can help explain the returns and risks of a portfolio or a single asset. Factors are used by investors to identify and exploit sources of excess returns, and they are central to many quantitative investment strategies.
  Each number in the factor represents a physics value to an instrument on a day.
  User will train a model to predict the next several days return based on the factor values of the previous days.

qlib_factor_strategy: |-
  Ensure that for every step of data processing, the data format (including indexes) is clearly explained through comments.
  Each transformation or calculation should be accompanied by a detailed description of how the data is structured, especially focusing on key aspects like whether the data has multi-level indexing, how to access specific columns or index levels, and any operations that affect the data shape (e.g., `reset_index()`, `groupby()`, `merge()`).
  This step-by-step explanation will ensure clarity and accuracy in data handling. For example:
  Note: The examples below are for explanation only. In this project, you should preserve the MultiIndex(`datetime`, `instrument`) contract and avoid index-changing operations unless explicitly required.
  1. **Start with multi-level index**:  
    ```python
    # The initial DataFrame has a multi-level index with 'datetime' and 'instrument'.
    # To access the 'datetime' index, use df.index.get_level_values('datetime').
    datetime_values = df.index.get_level_values('datetime')
    ```

  2. **Reset the index if necessary**:  
    ```python
    # Resetting the index to move 'datetime' and 'instrument' from the index to columns.
    # This operation flattens the multi-index structure.
    df = df.reset_index()
    ```

  3. **Perform groupby operations**:  
    ```python
    # Grouping by 'datetime' and 'instrument' to aggregate the data.
    # After groupby, the result will maintain 'datetime' and 'instrument' as a multi-level index.
    df_grouped = df.groupby(['datetime', 'instrument']).sum()
    ```

  4. **Ensure consistent datetime formats**:  
    ```python
    # Before merging, ensure that the 'datetime' column in both DataFrames is of the same format.
    # Convert to datetime format if necessary.
    df['datetime'] = pd.to_datetime(df['datetime'])
    other_df['datetime'] = pd.to_datetime(other_df['datetime'])
    ```

  5. **Merge operations**:  
    ```python
    # When merging DataFrames, ensure you are merging on both 'datetime' and 'instrument'.
    # If these are part of the index, reset the index before merging.
    merged_df = pd.merge(df, other_df, on=['datetime', 'instrument'], how='inner')
    ```

qlib_factor_simulator: |-
  The factors will be sent into Qlib to train a model to predict the next several days return based on the factor values of the previous days. 
  Qlib is an AI-oriented quantitative investment platform that aims to realize the potential, empower research, and create value using AI technologies in quantitative investment, from exploring ideas to implementing productions. Qlib supports diverse machine learning modeling paradigms. including supervised learning, market dynamics modeling, and RL.
  User will use Qlib to automatically do the following things:
  1. generate a new factor table based on the factor values.
  2. train a model like LightGBM, CatBoost, LSTM or simple PyTorch model to predict the next several days return based on the factor values.
  3. build a portfolio based on the predicted return based on a strategy.
  4. evaluate the portfolio's performance including the return, sharpe ratio, max drawdown, and so on.

qlib_factor_rich_style_description : |-
  ### R&D Agent-Qlib: Automated Quantitative Trading & Iterative Factors Evolution Demo

  #### [Overview](#_summary)

  The demo showcases the iterative process of hypothesis generation, knowledge construction, and decision-making. It highlights how financial factors evolve through continuous feedback and refinement.

  #### [Automated R&D](#_rdloops)

  - **[R (Research)](#_research)**
    - Iterative development of ideas and hypotheses.
    - Continuous learning and knowledge construction.

  - **[D (Development)](#_development)**
    - Progressive implementation and code generation of factors.
    - Automated testing and validation of financial factors.

  #### [Objective](#_summary)

  To demonstrate the dynamic evolution of financial factors through the Qlib platform, emphasizing how each iteration enhances the accuracy and reliability of the resulting financial factors.

qlib_factor_from_report_rich_style_description : |-
  ### R&D Agent-Qlib: Automated Quantitative Trading & Factor Extraction from Financial Reports Demo

  #### [Overview](#_summary)

  This demo showcases the process of extracting factors from financial research reports, implementing these factors, and analyzing their performance through Qlib backtest, continually expanding and refining the factor library.

  #### [Automated R&D](#_rdloops)

  - **[R (Research)](#_research)**
    - Iterative development of ideas and hypotheses from financial reports.
    - Continuous learning and knowledge construction.

  - **[D (Development)](#_development)**
    - Progressive factor extraction and code generation.
    - Automated implementation and testing of financial factors.

  #### [Objective](#_summary)

  <table border="1" style="width:100%; border-collapse: collapse;">
    <tr>
      <td> <strong>Innovation </strong></td>
      <td>Tool to quickly extract and test factors from research reports.</td>
    </tr>
    <tr>
      <td> <strong>Efficiency </strong></td>
      <td>Rapid identification of valuable factors from numerous reports.</td>
    </tr>
    <tr>
      <td> <strong>Outputs </strong></td>
      <td>Expand and refine the factor library to support further research.</td>
    </tr>
  </table>

qlib_factor_experiment_setting: |-
  | Dataset | Model    | Factors       | Data Split                                    |
  |---------|----------|---------------|-------------------------------------------------|
  | AIstock A-share (non-ST, non-delisted)  | GRU_TimeSeries_Model | Alpha158 Plus + AIstock factors | Train: 2010-01-07 to 2018-12-31 <br> Valid: 2019-01-01 to 2020-12-31 <br> Test &nbsp;: 2021-01-01 to 2025-12-01 |

  **Important Note: Stock Code Format**
  - Although the dataset name is "AIstock A-share", all original HDF5/Parquet data in `instrument` are already unified in **Qlib style** (e.g., `000001.SZ`, `600000.SH`).
  - **Prohibited** from performing any format conversion logic in the factor script.

  #### Computing Resources and Training Load Suggestions (Please prioritize meeting the following requirements to fully utilize local 12-core 24-thread + GPU)
  - **Training Rounds and Batch Size**:
    - For main experiments, avoid using overly small configurations (e.g., `n_epochs < 100`, `batch_size < 256`).
    - Recommended configuration range: `n_epochs` in `200~300`; `batch_size` prioritizes `512` (if memory is insufficient, it can be reduced to `256`).
  - **Parallelism Settings (CPU)**:
    - For components supporting `n_jobs`, prioritize setting to `n_jobs: 12` (close to the number of physical cores).
    - If YAML contains `workers` / `num_workers` / `processes` fields, set them between `8~12`, avoiding far exceeding the number of CPU cores.
  - **GPU Usage**:
    - For PyTorch-based time-series models (e.g., `GRU_TimeSeries_Model`), ensure `use_GPU: True`, `device: "cuda:0"`, and prohibit changing to `cpu`.
  - **Chain Stability Priority**:
    - Before increasing training load, first use smaller loops (e.g., `--loop-n 1`) to confirm the entire factor and Qlib training chain is fully connected:
      - Use the actual existing stock pool in the snapshot (usually `instruments: all`).
      - All factors can successfully calculate and generate `result.h5` on `daily_pv.h5`.
  - Only after the entire pipeline no longer encounters basic errors (e.g., `$close` / stock pool non-existence), gradually increase `n_epochs`, `batch_size`, and parallelism.

  #### Stock Pool Screening and Daily Indicator Factor Priority Usage Principle
  - In the factor and strategy evolution process, **prioritize using pre-computed daily_basic factor tables (valuation, market value, liquidity, etc.) for robustness and risk control**, then perform multi-factor modeling and stock selection on relatively "tradable/interpretable" samples:
    - Prioritize usage: exposure control (size/liquidity), winsorize/clip, hierarchical/group neutralization, and punishment for extreme tail samples (filtering should be the last resort).
    - Before adding new factors, ensure the basic factor set no longer exhibits systemic collapse (e.g., all NaN or significantly negative returns) in IC and backtest stability.

  #### Strategy Evolution Priority (When IC is consistently NaN or returns are significantly negative)
  - If in recent rounds of experiments, **cross-sectional IC is mostly NaN/close to 0, and portfolio annualized returns are significantly negative, with large maximum drawdowns**, prioritize checking and evolving the following directions rather than blindly switching to more complex time-series structures:
    1. **First, refine factors and labels (signal quality priority)**:
       - Check if factors are approximately constant, overly sparse, or if alignment/merge/dropna causes effective sample collapse.
       - Check and optimize labels: reasonably select the prediction window (e.g., 1D/5D/10D returns), and clearly define whether it's absolute return or excess return, ensuring evaluation metrics and label formats are consistent.
    2. **Use basic factors for robustness and risk purposes**:
       - `daily_basic` (valuation/market value/liquidity) prioritizes exposure control and stability constraints (filtering only when necessary).
       - `ae_recon_error_10d` is more suitable as an anomaly detection/risk factor participating in punishment or filtering, rather than solely bearing the main stock selection signal.
    3. **Control factor quantity and correlation, first run stable Tabular baseline**:
       - Avoid a large number of highly correlated or extremely sparse new factors.
       - First, verify in LightGBM/CatBoost/simple MLP, etc., Tabular baseline that IC is no longer NaN and returns are no longer systemically negative, then consider introducing more complex time-series structures.

qlib_model_background: |-
  The model is a machine learning or deep learning structure used in quantitative investment to predict the returns and risks of a portfolio or a single asset. Models are employed by investors to generate forecasts based on historical data and identified factors, which are central to many quantitative investment strategies.
  Each model takes the factors as input and predicts the future returns. Usually, the bigger the model is, the better the performance would be.
  The model is defined in the following parts:
  1. Name: The name of the model.
  2. Description: The description of the model.
  3. Architecture: The detailed architecture of the model, such as neural network layers or tree structures.
  4. Hyperparameters: The hyperparameters used in the model.
  5. Training_hyperparameters: The hyperparameters used during the training process.
  6. ModelType: The type of the model, "Tabular" for tabular model and "TimeSeries" for time series model.
  The model should provide clear and detailed documentation of its architecture and hyperparameters. One model should statically define one output with a fixed architecture and hyperparameters.

  {% if runtime_environment is not none %}
  ====== Runtime Environment ======
  You have following environment to run the code:
  {{ runtime_environment }}
  {% endif %}

qlib_model_simulator: |-
  The models will be sent into Qlib to train and evaluate their performance in predicting future returns. Hypothesis is improved upon checking the feedback on the results. 
  Qlib is an AI-oriented quantitative investment platform that aims to realize the potential, empower research, and create value using AI technologies in quantitative investment, from exploring ideas to implementing productions. Qlib supports diverse machine learning modeling paradigms, including supervised learning, market dynamics modeling, and reinforcement learning (RL).
  User will use Qlib to automatically perform the following tasks:
  1. Generate a baseline factor table.
  2. Train the model defined in your class Net to predict the next several days' returns based on the factor values.
  3. Build a portfolio based on the predicted returns using a specific strategy.
  4. Evaluate the portfolio's performance, including metrics such as return, IC, max drawdown, and others.
  5. Iterate on growing the hypothesis to enable model improvements based on performance evaluations and feedback.

qlib_model_rich_style_description: |-
  ### Qlib Model Evolving Automatic R&D Demo

  #### [Overview](#_summary)

  The demo showcases the iterative process of hypothesis generation, knowledge construction, and decision-making in model construction in quantitative finance. It highlights how models evolve through continuous feedback and refinement.

  #### [Automated R&D](#_rdloops)

  - **[R (Research)](#_research)**
    - Iteration of ideas and hypotheses.
    - Continuous learning and knowledge construction.

  - **[D (Development)](#_development)**
    - Evolving code generation and model refinement.
    - Automated implementation and testing of models.

  #### [Objective](#_summary)

  To demonstrate the dynamic evolution of models through the Qlib platform, emphasizing how each iteration enhances the accuracy and reliability of the resulting models. 

qlib_model_experiment_setting: |-
  | Dataset | Model    | Factors       | Data Split                                    |
  |---------|----------|---------------|-------------------------------------------------|
  | AIstock A-share (non-ST, non-delisted)  | 例如 GRU_TimeSeries_Model（也可替换为 LGB/MLP/Transformer 等其它模型） | 20 factors (Alpha158)  | Train: 2010-01-07 to 2018-12-31 <br> Valid: 2019-01-01 to 2020-12-31 <br> Test &nbsp;: 2021-01-01 to 2025-12-01 |

  **Important Note: Stock Code Format**
  - Although the dataset name is "AIstock A-share", all data sources in `instrument` are already unified in **Qlib style** (e.g., `000001.SZ`, `600000.SH`).
  - **Prohibited** from performing format conversion in the research and development process.

model_hypothesis_specification: |-
  1. First, observe and analyze the overall experimental progression in `hypothesis_and_feedback`. Analyze where the previous model designs were inadequate — whether it was due to parameter settings, architectural flaws, or a lack of novelty (proposing entirely new concepts is highly encouraged as long as they demonstrate effectiveness).
  2. Second, `last_hypothesis_and_feedback` and `sota_hypothesis_and_feedback` are key references you should pay close attention to. You can choose to optimize based on either of them or generate new ideas to form hypotheses and experiments.
  3. If there is no prior experiment or result available at the beginning, you can start by implementing a simple and small architecture.
  4. If a series of attempts fail to achieve SOTA, consider exploring entirely new directions; at this point, it is acceptable to return to simple architectures.
  5. Focus exclusively on the architecture of PyTorch models. Each hypothesis should specifically address architectural decisions, such as layer configurations, activation functions, regularization methods, and overall model structure. DO NOT do any feature-specific processing. Instead, you can propose innovative transformations on the input time-series data to enhance model training effectiveness.
  6. Avoid including aspects unrelated to architecture, such as input features or optimization strategies.
  7. Sometimes, when training performance is poor, adjusting hyperparameters can also be an effective strategy for improvement.
  8. Use standard libraries for baseline models, but also explore custom architecture designs to investigate novel structures. After sufficient trials with traditional models, aim for innovation comparable to top-tier AI conferences (NeurIPS, ICLR, ICML, SIGKDD, etc.) in time series modeling.

factor_hypothesis_specification: |-
  1. **1-5 Factors per Generation:**
    - Ensure each generation produces 1-5 factors.
    - Balance simplicity and complexity to build a robust factor library.
    - Make full use of the financial data provided to you instead of focusing solely on a specific field.
  2. **Simple and Effective Factors First:**
    - Start with factors that are simple, easy to achieve and likely effective.
    - Concisely explain why these factors are expected to work.
    - Avoid complex or combined factors initially.
  3. **Gradual Complexity Increase:**
    - Introduce more complex factors (e.g. machine learning based factors, factors use mult-dimentional factor raw data, etc.) as more experimental results are gathered.
    - Combine factors only after simpler ones are tested and validated.
  4. **New Directions and Optimizations:**
    - If multiple consecutive iterations fail to produce factors surpassing SOTA, consider switching to a new direction and can starting with simple factors again.
    - If optimizing a specific type of factor, proceed from simple to complex.
  5. Note
    - Highlight that factors surpassing SOTA are included in the library to avoid re-implementation.
    - No matter how many factors you plan to generate, only reply with one set of hypothesis and reason. The hypothesis can include the proposal of multiple factors at the same time.

factor_experiment_output_format: |-
  The output should follow JSON format. The schema is as follows:
  {
      "factor name 1": {
          "description": "description of factor 1, start with its type, e.g. [Momentum Factor]",
          "formulation": "latex formulation of factor 1",
          "variables": {
              "variable or function name 1": "description of variable or function 1",
              "variable or function name 2": "description of variable or function 2"
          }
      },
      "factor name 2": {
          "description": "description of factor 2, start with its type, e.g. [Machine Learning based Factor]",
          "formulation": "latex formulation of factor 2",
          "variables": {
              "variable or function name 1": "description of variable or function 1",
              "variable or function name 2": "description of variable or function 2"
          }
      }
      # Don't add ellipsis (...) or any filler text that might cause JSON parsing errors here!
  }

model_experiment_output_format: |-
  So far please only design one model to test the hypothesis!
  The output should follow JSON format. The schema is as follows (value in training_hyperparameters is a basic setting for reference, you CAN CHANGE depends on the previous training log):
  {
    "model_name (The name of the model)": {
        "description": "A detailed description of the model",
        "formulation": "A LaTeX formula representing the model's formulation",
        "architecture": "A detailed description of the model's architecture, e.g., neural network layers or tree structures",
        "variables": {
            "\\hat{y}_u": "The predicted output for node u",
            "variable_name_2": "Description of variable 2",
            "variable_name_3": "Description of variable 3"
        },
        "hyperparameters": {
            "hyperparameter_name_1": "value of hyperparameter 1",
            "hyperparameter_name_2": "value of hyperparameter 2",
            "hyperparameter_name_3": "value of hyperparameter 3"
        },
        "training_hyperparameters" {  # All values are for reference; you can set them yourself
            "n_epochs": "100",
            "lr": "1e-3",
            "early_stop": 10,
            "batch_size": 256,
            "weight_decay": 1e-4,
        }
        "model_type": "Tabular or TimeSeries"  # Should be one of "Tabular" or "TimeSeries"
    },
  }

qlib_factor_interface: |-
  Your python code should follow the interface to better interact with the user's system.
  Your python code should contain the following part: the import part, the function part, and the main part. You should write a main function name: "calculate_{function_name}" and call this function in "if __name__ == __main__" part. Don't write any try-except block in your python code. The user will catch the exception message and provide the feedback to you.
  User will write your python code into a python file and execute the file directly with "python {your_file_name}.py". You should calculate the factor values and save the result into a HDF5(H5) file named "result.h5" in the same directory as your python file. The result file is a HDF5(H5) file containing a pandas dataframe. The index of the dataframe is the "datetime" and "instrument", and the single column name is the factor name,and the value is the factor value. The result file should be saved in the same directory as your python file.

  【统一因子脚本模板（必须遵守，LLM 只能在中间区域写逻辑）】
  - 因子脚本应严格采用如下整体骨架，其中 **仅允许在标记的“FACTOR COMPUTATION AREA”内编写/修改代码**.
    - 在该区域内，你可以根据本轮假设自由设计因子与信号逻辑，不局限于简单的动量/波动率/量价关系；
    - 说明：Alpha158/AE/daily_basic 等特征通常在 Qlib 训练/回测侧由 DataHandler/YAML 进行拼接并作为模型输入；单个 `factor.py` 的运行时输入默认只保证 `daily_pv.h5`，若需要使用 `daily_basic/moneyflow` 等静态字段，必须显式读取并 join `static_factors.parquet`；
    - 本轮实验不强制策略必须依赖“量价因子”，重点在于保证数据格式与索引 contract 正确的前提下，充分释放模型与因子的演进空间。

    ```python
    import pandas as pd
    import numpy as np

    def calculate_{function_name}():
        """根据给定因子定义计算因子值，并写入 result.h5"""

        # 1. 读取数据并按索引排序（索引应为 MultiIndex(datetime, instrument)）
        df = pd.read_hdf("daily_pv.h5", key="data").sort_index()

        # 2. 统一重命名（见下文“数据加载与字段名规范”），后续代码只使用不带 $ 的列名
        rename_map = {
            "$open": "open",
            "$high": "high",
            "$low": "low",
            "$close": "close",
            "$volume": "volume",
            "$amount": "amount",
            "$factor": "factor",
        }
        df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})

        # 3. 再次确保索引按 (datetime, instrument) 排序
        df = df.sort_index()

        # 4. ==== BEGIN FACTOR COMPUTATION AREA ====
        # 在此区域内，你可以自由使用 df 计算出一个或多个与 df.index 对齐的 Series/列：
        # - 不允许修改 df.index 结构
        # - 只允许对 df.columns / 中间 Series 做变换
        # - 你可以根据当前任务需要，灵活组合价格、成交量、AE 因子、daily_basic 等多种信号，探索不同的因子形态与策略风格；
        # - 不要求本区域实现的因子一定是“简单收益率”或“纯量价指标”，可以是截面打分、分位数信号、非线性组合等。

        # 示意：以下只是一个占位示例，请在实际任务中用你的真实逻辑完全替换掉该 Series 的构造。
        series = df["close"] / df["close"].groupby(level="instrument").shift(1) - 1

        # 对于 groupby+rolling 的典型模式，请使用：
        # s = df["x"].groupby(level="instrument").rolling(window=K, min_periods=K).func(...)
        # s = s.reset_index(level=0, drop=True)  # 恢复为与 df.index 对齐

        # ==== END FACTOR COMPUTATION AREA ====

        # 5. 构造结果 DataFrame：索引必须与 df.index 完全一致
        result_df = pd.DataFrame(index=df.index)
        result_df["{function_name}"] = series.astype("float32")

        # 6. 索引名称必须直接继承 df.index.names，禁止手写 ["datetime", "instrument"]
        result_df.index.names = df.index.names

        # 7. 按索引排序并写入 result.h5
        result_df = result_df.sort_index()
        result_df.to_hdf("result.h5", key="data", mode="w")

        return result_df

    if __name__ == "__main__":
        calculate_{function_name}()
    ```
  - **严禁** 在上述模板之外随意增删“读取/输出/索引处理”代码:
    - 不要重写 `result_df = pd.DataFrame(index=df.index)` 这一行的模式；
    - 不要手工写 `result_df.index.names = ["datetime", "instrument"]`，而是始终使用 `df.index.names`；
    - 不要对结果进行 `reset_index(drop=True)` 或 `droplevel` / `swaplevel` 等会改变索引结构的操作.
  - 所有因子实现都应遵守统一的 **输出 contract**：
    - `index`：MultiIndex(`datetime`, `instrument`)，与 `df.index` 完全一致并已排序；
    - `columns`：一列或多列 `float32` 类型的因子列；
    - 输出文件固定为当前目录下的 `result.h5`，由 Qlib 上游统一加载.

  【数据加载与字段名规范（必须严格遵守，用于避免 $close / close 列名错误）】
  - 因子实现只能从当前工作目录下的 `daily_pv.h5` 读取数据，该文件索引为 MultiIndex(`datetime`, `instrument`)，列名采用 Qlib 风格:
    `$open`, `$high`, `$low`, `$close`, `$volume`, `$amount`, `$factor`.
  - **可选静态字段（daily_basic / 资金流原始字段）**：当前工作目录下可能存在 `static_factors.parquet`（由上游数据准备阶段复制到因子执行目录），其索引同样为 MultiIndex(`datetime`, `instrument`)，包含 daily_basic / moneyflow 等原始字段（通常以 `db_` / `mf_` 等前缀命名）。
    - **列名白名单（硬约束）**：你只能使用 `static_factors_schema.csv` / `static_factors_schema.json` 中列出的字段名（系统会在数据目录中提供该 schema 文件的描述）。严禁凭经验“编造/猜测”字段名（例如 `mf_net_inflow_1d`、`mf_large_buy_ratio` 等）。
    - 如果你的因子定义确实依赖这些字段（例如流通市值、流通股本、换手率、资金净流入等），你 **必须** 显式读取并 join。为了节省内存，**严禁全量加载**，必须通过 `columns` 参数仅读取必要的列：
      ```python
      # 必须：仅读取计算所需的列，以避免 OOM (static_factors.parquet 很大)
      required_static_cols = ["db_circ_mv", "mf_net_amt"] # 示例：按需替换为实际所需列名
      static_df = pd.read_parquet("static_factors.parquet", columns=required_static_cols).sort_index()
      
      # 注意：当前数据源的 instrument 已经是 Qlib 风格（600000.SH/000001.SZ），与 static_factors.parquet 完全对齐.
      # 直接执行 join 即可，无需进行格式转换.
      # 使用 join 将所需列合并到主 DataFrame 中
      df = df.sort_index().join(static_df, how="left")
      ```
    - **资金净流入等派生量（推荐做法）**：如果你需要“资金净流入/净流入占比/5日净流入”等字段，但 schema 中没有直接提供，请基于 `mf_*_buy_amt` / `mf_*_sell_amt` 组合自行派生（例如把 `sm/md/lg/elg` 四档买入金额相加减去卖出金额），并可进一步除以 `amount` 或 `db_circ_mv` 做归一化，再做 rolling 聚合。
    - 若 `static_factors.parquet` 不存在或缺少所需列，请直接报错并在下一轮改写因子定义（见下文约束），严禁用硬编码常数“拍脑袋补齐”。
  - 在你的 `factor.py` 中，**必须首先执行如下统一重命名逻辑**，把带 `$` 前缀的字段映射为不带 `$` 的业务字段名，后续代码一律使用重命名后的字段:
    ```python
    import pandas as pd

    df = pd.read_hdf("daily_pv.h5", key="data").sort_index()

    rename_map = {
        "$open": "open",
        "$high": "high",
        "$low": "low",
        "$close": "close",
        "$volume": "volume",
        "$amount": "amount",
        "$factor": "factor",
    }
    df = df.rename(columns={k: v for k, v in rename_map.items() if k in df.columns})
    ```
  - **后续所有代码中，只能使用不带 `$` 的字段名**，例如：`df["close"]`、`df["volume"]`、`df["db_turnover_rate"]`、`df["mf_lg_buy_amt"]`。严禁混用 `df["$close"]` 和 `df["close"]`.

  【严禁硬编码替代变量（必须严格遵守）】
  - 如果核心价量字段（例如 `close/open/high/low/volume/amount`）缺失：
    - **必须** `raise ValueError` 明确指出缺失字段；
  - 如果你希望使用 `static_factors.parquet` 中的可选静态字段（例如 `db_*`/`mf_*`），但实际不存在或 join 后全为空：
    - 优先改写因子定义为仅依赖当前可获得字段；
    - 或在不破坏输出 contract 的前提下采用“降级版本”（例如退回到纯价量信号），但严禁用常数/拍脑袋值把公式凑出来.
  - **总原则**：严禁为缺失字段“编造/猜测/假设”一个固定值或常数分母来把公式凑出来.
  - 在实现依赖特定字段的因子前，必须先做列存在性检查：
    ```python
    required_cols = ["close", "volume", "db_circ_mv"]
    missing = [c for c in required_cols if c not in df.columns]

    if missing:
        raise ValueError(f"Missing columns: {missing}. Please redesign factor using available fields.")
    ```

  - 当前项目中，`daily_pv.h5` 已在数据导出阶段统一剔除了所有 ST 和 *ST 股票，以及所有已退市或当前暂停上市的股票，其股票池与 Qlib bin 数据集（例如 `qlib_bin_20251209`）完全对齐。你在因子实现中可以默认研究与回测使用的是同一可交易股票集合，无需在代码中再次按 ST/退市条件过滤股票.
  - 因子结果必须保持索引为 MultiIndex(`datetime`, `instrument`)，`index.names == ["datetime", "instrument"]`，并通过：
    ```python
    result_df.to_hdf("result.h5", key="data", mode="w")
    ```
    写入同一目录下的 `result.h5` 文件，列为一个或多个 `float32` 类型的因子列.
  - 在 Qlib 回测与联合因子实验的 YAML 模板中，还会通过 `StaticDataLoader/NestedDataLoader` 自动加载若干**预计算因子表**（无需在每个 `factor.py` 中重复计算），例如：
    - 全局自编码器异常检测因子表：`ae_recon_error_10d`（10 日重构误差），路径类似 `.../factors/ae_recon_error_10d/result.h5`；
    - 每日指标预计算因子表：`daily_basic_factors/result.h5`，包含估值、市值、流动性等 `db_*` 派生因子；
    - 后续可能扩展的资金流因子表：`capital_flow_daily/result.h5` 等.
    这些预计算表在 Qlib 侧作为额外特征自动拼接到模型输入中，用于联合因子/策略演进；你在单一 `factor.py` 中只需专注于基于 `daily_pv.h5` 的本地因子实现，不必在脚本里重复实现 AE/daily_basic/资金流整表计算逻辑.

qlib_factor_output_format: |-
  Your output should be a pandas dataframe similar to the following example information:
  <class 'pandas.core.frame.DataFrame'>
  MultiIndex: 40914 entries, (Timestamp('2020-01-02 00:00:00'), '000001.SZ') to (Timestamp('2021-12-31 00:00:00'), '000750.SZ')
  Data columns (total 1 columns):
  #   Column            Non-Null Count  Dtype  
  ---  ------            --------------  -----  
  0   your factor name  40914 non-null  float32
  dtypes: float32(1)
  memory usage: <ignore>
  Notice: The non-null count is OK to be different to the total number of entries since some instruments may not have the factor value on some days.
  One possible format of `result.h5` may be like following:
  datetime    instrument
  2020-01-02  000001.SZ     -0.001796
              000166.SZ      0.005780
              600686.SH      0.004228
              600712.SH      0.001298
              600728.SH      0.005330
                              ...
  2021-12-31  000750.SZ      0.000000
              000776.SZ      0.002459

qlib_model_interface: |-
  Your python code should follow the interface to better interact with the user's system.
  You code should contain several parts:
  1. The import part: import the necessary libraries.
  2. A class which is a sub-class of pytorch.nn.Module. This class should should have a init function and a forward function which inputs a tensor and outputs a tensor.
  3. Set a variable called "model_cls" to the class you defined.

  The user will save your code into a python file called "model.py". Then the user imports model_cls in file "model.py" after setting the cwd into the directory:
  ```python
  from model import model_cls
  ```
  So your python code should follow the pattern:
  ```python
  class XXXModel(torch.nn.Module):
      ...
  model_cls = XXXModel
  ```

  The model can be configured as either "Tabular" for tabular models or "TimeSeries" for time series models. For a tabular model, the input shape is (batch_size, num_features), while for a time series model, the input shape is (batch_size, num_timesteps, num_features). In both cases, the output shape of the model should be (batch_size, 1).
  `num_features` will be directly set for the model based on the input data shape.
  User will initialize the tabular model with the following code:
  ```python
  model = model_cls(num_features=num_features)
  ```
  User will initialize the time series model with the following code:
  ```python
  model = model_cls(num_features=num_features, num_timesteps=num_timesteps)
  ```
  No other parameters will be passed to the model so give other parameters a default value or just make them static.

  Don't write any try-except block in your python code. The user will catch the exception message and provide the feedback to you. Also, don't write main function in your python code. The user will call the forward method in the model_cls to get the output tensor.

  Please notice that your model should only use current features as input. The user will provide the input tensor to the model's forward function.

qlib_model_output_format: |-
  Your output should be a tensor with shape (batch_size, 1). 
  The output tensor should be saved in a file named "output.pth" in the same directory as your python file.
  The user will evaluate the shape of the output tensor so the tensor read from "output.pth" should be 8 numbers.

factor_feedback_generation:
  system: |-
    You are a professional financial result analysis assistant in data-driven R&D.
    The task is described in the following scenario:

    {{ scenario }}

    In this test scenario, the user is mainly interested in improving an **A-share long-only stock selection strategy** on **daily data over a multi-year backtest window**, with the following requirements:
      - Investment universe: all A-share stocks listed on the Shanghai Stock Exchange (SSE) and Shenzhen Stock Exchange (SZSE), **excluding all ST and *ST stocks**.
      - Portfolio construction: on each rebalancing date, **select up to 50 stocks** from the eligible universe and build a **dynamic-weighted long-only portfolio** (no short selling, no leverage).
      - Holding period: a medium-term horizon of **5–20 trading days** for each position on a **daily trading frequency**; in practice, if a single position reaches **+15% profit**, take partial profit (e.g., reduce 1/3); if it reaches **+25%**, take partial profit again; if it reaches **+35%**, take profit and close the position. If the unrealized loss reaches **-10%**, a stop-loss is triggered and the position should be **liquidated immediately** (risk threshold).
      - Performance target: over the backtest period, the typical 5–20 day holding-period return should be **around 5%–10%**, while the **maximum portfolio drawdown should be no greater than 10%** (the smaller, the better).
      - The strategy should primarily rely on cross-sectional and time-series information from price, volume and volatility, and may combine multiple factors (multi-factor stock selection).
      - Risk controls: maximum position ratio of 90% (max_position_ratio=0.90), minimum score threshold of 0.10 (min_score=0.10) for stock selection, and automatic clearing of stocks with scores below 0.10.
    When giving feedback and summarizing results in this scenario, please pay special attention to these constraints and explicitly comment on how the current experiment moves the strategy closer to or away from these goals.
    All final textual explanations and natural-language summaries in your feedback should be written in **Chinese** (use concise professional Chinese), while keeping JSON keys and numeric values unchanged.

    You will receive a hypothesis, multiple tasks with their factors, their results, and the SOTA result.
    Your feedback should specify whether the current result supports or refutes the hypothesis, compare it with previous SOTA (State of the Art) results, and suggest improvements or new directions.

    Please understand the following operation logic and then make your feedback that is suitable for the scenario:
      1. Logic Explanation:
        a) All factors that have surpassed SOTA in previous attempts will be included in the SOTA factor library.
        b) New experiments will generate new factors, which will be combined with the factors in the SOTA library.
        c) These combined factors will be backtested and compared against the current SOTA to enable continuous iteration.
      2. Development Directions:
        a) New Direction: Propose a new factor direction for exploration and development.
        b) Optimization of Existing Direction:
          - Suggest further improvements to that factor (this can include further optimization of the factor or proposing a direction that combines better with the factor).
          - Avoid re-implementing previous factors as those that surpassed SOTA are already included in the factor library and will be used in each run.
      3. Final Goal: To continuously accumulate factors that surpass each iteration to maintain the best SOTA.

    When judging the results:
      1. Any small improvement should be considered for inclusion as SOTA (set `Replace Best Result` as yes).
      2. If the new factor(s) shows an improvement in the annualized return, recommend it to replace the current best result.
      3. Minor variations in other metrics are acceptable as long as the annualized return improves.

    Consider Changing Direction for Significant Gaps with SOTA:
      - If the new results significantly differ from the SOTA, consider exploring a new direction (write new type factors).
      - Avoid re-implementing previous factors as those that surpassed SOTA are already included in the factor library and will be used in each run.

    Please provide detailed and constructive feedback for future exploration.
    Respond in JSON format. Example JSON structure for Result Analysis:
    {
      "Observations": "Your overall observations here",
      "Feedback for Hypothesis": "Observations related to the hypothesis",
      "New Hypothesis": "Your new hypothesis here",
      "Reasoning": "Reasoning for the new hypothesis",
      "Replace Best Result": "yes or no"
    }

    重要实现约束规则（必须严格遵守）：
      1. 依赖与导入相关：
        - 不要导入 h5py 模块。保存 HDF5 文件时，只允许使用 pandas.DataFrame.to_hdf 接口，代码中不需要也不允许显式 import h5py。
        - 不要引入当前环境中不一定存在的第三方库（例如额外的深度学习框架、数据库驱动等），除非在本项目中已明确使用并保证已安装。优先使用标准库、numpy、pandas、torch 等常用基础依赖。
      2. 异常处理相关：
        - 在因子实现函数中，禁止使用 try/except 包裹整个主逻辑。出现错误时应直接抛出，由外层 RD-Agent/QLib 框架捕获和记录日志。
        - 只有在极少数需要精细处理的局部逻辑中，才可以使用小范围的 try/except，但不得吞掉异常信息或返回静默的错误结果。
      3. 数据来源与示例数据相关：
        - 因子实现必须基于框架传入的数据（例如 QLib 提供的 DataFrame），不允许在实现中使用 np.random 等方式构造完全随机的演示数据作为真实价格序列。
        - 如果需要示例，请仅在注释或说明中给出，不在实际执行代码路径中生成虚拟数据。
      4. 滚动窗口与 min_periods 设置：
        - 使用 rolling(window=...) 计算移动平均、波动率、动量等因子时，min_periods 应与窗口长度一致，或不显式设置（使用默认值），以避免在样本数量不足时返回不可靠的数值。
        - 对于窗口长度内不足的数据（前若干天），允许保留为 NaN，后续由回测引擎或上层逻辑自然处理这些缺失值，不要为了“填满数据”随意填充虚假值。
      5. 接口规范与可执行性：
        - 必须严格遵守 RD-Agent/QLib 约定的因子函数签名，不要修改函数名、入参、返回类型。
        - 生成的代码必须能够在无额外手工修改的情况下，直接在当前 RD-Agent 环境中执行，不依赖人工删除 import、try/except 或手工改动逻辑。
      6. Pandas API 使用约束：
        - 不要虚构 pandas 中不存在的方法（例如在 Rolling 对象上使用不存在的 combine 等方法）。
        - 计算相关系数、协方差等统计量时，应优先使用 pandas 提供的标准接口，例如 Series.rolling().corr()、cov() 等，而不是自定义不存在的 API。
        - 如果不确定某个 API 是否存在，请改用已知、基础的 pandas/numpy 操作组合实现，不要编造新方法名。

  user: |-
    Target hypothesis:
    {{ hypothesis_text }}
    Tasks and Factors:
    {% for task in task_details %}
      - {{ task.factor_name }}: {{ task.factor_description }}
        - Factor Formulation: {{ task.factor_formulation }}
        - Variables: {{ task.variables }}
        - Factor Implementation: {{ task.factor_implementation }}
        {% if task.factor_implementation == "False" %}
        **Note: This factor was not implemented in the current experiment. Only the hypothesis for implemented factors can be verified.**
        {% endif %}
    {% endfor %}
    Combined Results:
    {{ combined_result }}

    Analyze the combined result in the context of its ability to:
    1. Support or refute the hypothesis.
    2. Show improvement or deterioration compared to the SOTA experiment.

    Note: Only factors with 'Factor Implementation' as True are implemented and tested in this experiment. If 'Factor Implementation' is False, the hypothesis for that factor cannot be verified in this run.

model_feedback_generation:
  system: |-
    You are a professional quantitative analysis assistant in top-tier hedge fund.

    The task is described in the following scenario:
    {{ scenario }}

    In this test scenario, the user is mainly interested in improving an **A-share long-only stock selection strategy** on **daily data over a multi-year backtest window**, with the following requirements:
      - Investment universe: all A-share stocks listed on the Shanghai Stock Exchange (SSE) and Shenzhen Stock Exchange (SZSE), **excluding all ST and *ST stocks**.
      - Portfolio construction: on each rebalancing date, **select up to 50 stocks** from the eligible universe and build a **dynamic-weighted long-only portfolio** (no short selling, no leverage).
      - Holding period: a medium-term horizon of **5–20 trading days** for each position (for implementation, you can adopt a fixed holding period such as 10 or 20 days in the backtest framework).
      - Risk control: single-position **take-profit in tiers** at **+15% / +25% / +35%**; once reaching **-10% stop-loss** (risk liquidation threshold), the position should be **closed immediately**.
      - Performance target: over the backtest period, the typical 5–20 day holding-period return should be **around 5%–10%**, while the **maximum portfolio drawdown should be no greater than 10%** (the smaller, the better).
      - The strategy should primarily rely on cross-sectional and time-series information from price, volume and volatility, and may combine multiple factors (multi-factor stock selection).
      - Risk controls: maximum position ratio of 90% (max_position_ratio=0.90), minimum score threshold of 0.10 (min_score=0.10) for stock selection, and automatic clearing of stocks with scores below 0.10.
    When analyzing model performance, explicitly evaluate whether these objectives are being met or approached.
    All narrative parts of your feedback and final summary should be written in **Chinese** (concise professional Chinese), while JSON structure and field names must remain in English.

    You will receive a quantitative model hypothesis, its specific task description, and it market backtest result.
    Your feedback should specify whether the current result supports or refutes the hypothesis, compare it with previous SOTA results, examine the model's training logs to analyze whether there are issues with hyperparameter settings, and suggest improvements or new directions.

    Please provide detailed and constructive feedback.
    Example JSON Structure for Result Analysis:
    {
      "Observations": "First analyze the model's training logs to determine whether there are any issues with its parameter settings. Then clearly summarize the current results and the SOTA results with exact scores and any notable patterns. Limit your summary to no more than three concise, data-focused sentences.",
      "Feedback for Hypothesis": "Explicitly confirm or refute the hypothesis based on specific data points or performance trends. Limit to two sentences.",
      "New Hypothesis": "Propose a revised hypothesis, considering observed patterns and limitations in the current one. Limit to no more than two sentences.",
      "Reasoning": "Explain the rationale for the new hypothesis using specific trends or performance shifts. Be concise but technically complete. Limit to two sentences.",
      "Decision": <true or false>,
    }

    重要实现约束规则（必须严格遵守）：
      1. 依赖与导入相关：
        - 不要导入 h5py 模块。保存 HDF5 文件时，只允许使用 pandas.DataFrame.to_hdf 接口，代码中不需要也不允许显式 import h5py。
        - 不要引入当前环境中不一定存在的第三方库（例如额外的深度学习框架、数据库驱动等），除非在本项目中已明确使用并保证已安装。优先使用标准库、numpy、pandas、torch 等常用基础依赖。
      2. 异常处理相关：
        - 在模型实现函数中，禁止使用 try/except 包裹整个主逻辑。出现错误时应直接抛出，由外层 RD-Agent/QLib 框架捕获和记录日志。
        - 只有在极少数需要精细处理的局部逻辑中，才可以使用小范围的 try/except，但不得吞掉异常信息或返回静默的错误结果。
      3. 数据来源与示例数据相关：
        - 模型实现必须基于框架传入的数据（例如 QLib 提供的 DataFrame 或特征矩阵），不允许在实现中使用 np.random 等方式构造完全随机的演示数据作为真实价格或特征序列。
        - 如果需要示例，请仅在注释或说明中给出，不在实际执行代码路径中生成虚拟数据。
      4. 接口规范与可执行性：
        - 必须严格遵守 RD-Agent/QLib 约定的模型接口和函数签名，不要修改函数名、入参、返回类型。
        - 生成的代码必须能够在无额外手工修改的情况下，直接在当前 RD-Agent 环境中执行，不依赖人工删除 import、try/except 或手工改动逻辑。
      5. Pandas API 使用约束：
        - 不要虚构 pandas 中不存在的方法（例如在 Rolling 对象上使用不存在的 combine 等方法）。
        - 当模型内部需要做时间序列统计（如 rolling 相关性、协方差等）时，应优先使用 pandas 提供的标准接口，例如 Series.rolling().corr()、cov()，而不是自定义不存在的 API。
        - 如果不确定某个 API 是否存在，请改用已知、基础的 pandas/numpy 操作组合实现，不要编造新方法名。

  user: |-
    {% if sota_hypothesis %}
    # SOTA Round Information:
    Hypothesis: {{ sota_hypothesis.hypothesis }}
    Specific Task: {{ sota_task }}
    Code Implementation: {{ sota_code }}
    Result: {{ sota_result }}
    {% else %}
    # This is the first round. No previous information available. As long as the performance is not too negative (eg.ICIR is greater than 0), treat it as successful. Do not set the threshold too high.
    {% endif %}

    # Current Round Information:
    Hypothesis: {{ hypothesis.hypothesis }}
    Why propose this hypothesis: {{ hypothesis.reason }}
    Specific Task: {{ exp.sub_tasks[0].get_task_information() }}
    Code Implementation: {{ exp.sub_workspace_list[0].file_dict.get("model.py") }}
    Training Log: {{ exp.stdout }}
    Result: {{ exp_result }}

    # When judging the results:
    1. **Recommendation for Replacement:**
      - If the new model's performance shows an improvement in the annualized return, recommend it to replace the current SOTA result.
      - Minor variations in other metrics are acceptable as long as the annualized return improves.
    2.  Consider Changing Direction When Results Are Significantly Worse Than SOTA:
      - If the new results significantly worse than the SOTA, consider exploring a new direction, like change a model architecture.

action_gen:
  system: |-
    Quantitative investment is a data-driven approach to asset management that relies on mathematical models, statistical techniques, and computational methods to analyze financial markets and make investment decisions. Two essential components of this approach are factors and models.

    You are one of the most authoritative quantitative researchers at a top Wall Street hedge fund. I need your expertise to develop new factors and models that can enhance our investment returns. Based on the given context, I will ask for your assistance in designing and implementing either factors or a model.

    In the current testing scenario, the user is mainly interested in improving an **A-share long-only stock selection strategy** on **daily data over a multi-year backtest window**, with the following requirements:
      - Investment universe: all A-share stocks listed on the Shanghai Stock Exchange (SSE) and Shenzhen Stock Exchange (SZSE), **excluding all ST and *ST stocks**.
      - Portfolio construction: on each rebalancing date, **select up to 50 stocks** from the eligible universe and build a **dynamic-weighted long-only portfolio** (no short selling, no leverage).
      - Holding period: a medium-term horizon of **5–20 trading days** for each position on a **daily trading frequency**; in practice, if a single position reaches **+15% profit**, take partial profit (e.g., reduce 1/3); if it reaches **+25%**, take partial profit again; if it reaches **+35%**, take profit and close the position. If the unrealized loss reaches the **stop-loss threshold** or a **risk threshold**, the position should be **liquidated immediately**.
      - Performance target: over the backtest period, the typical 5–20 day holding-period return should be **around 5%–10%**, while the **maximum portfolio drawdown should be no greater than 10%** (the smaller, the better).
      - The strategy should primarily rely on cross-sectional and time-series information from price, volume and volatility, and may combine multiple factors (multi-factor stock selection).
    When deciding whether the next experiment should focus on factors or models, please consider which action is more likely to move the strategy towards these goals (higher 5–20 day holding-period return under the constraint of max drawdown ≤ 10%, and respecting the **tiered take-profit at +15% / +25% / +35% with stop-loss or risk liquidation** rules at the single-position level).

    You will receive a series of experiments, including their factors and models, and their results.
    Your task is to analyze the previous experiments and decide whether the next experiment should focus on factors or models.

    Example JSON Structure for your return:
    {
      "action": "factor" or "model",  # You must choose one of the two
    }

  user: |-
    {% if hypothesis_and_feedback|length == 0 %}
    It is the first round of hypothesis generation. The user has no hypothesis on this scenario yet.
    {% else %}
    The former hypothesis and the corresponding feedbacks are as follows:
    {{ hypothesis_and_feedback }}
    {% endif %}


    {% if last_hypothesis_and_feedback != "" %}
    Here is the last trial's hypothesis and the corresponding feedback. The main feedback includes a new hypothesis for your reference only. You should evaluate the entire reasoning chain to decide whether to adopt it, propose a more suitable hypothesis, or transfer and optimize it for another scenario (e.g., factor/model), since transfers are generally encouraged:
    {{ last_hypothesis_and_feedback }}
    {% endif %}

