# 因子演进中增加模型选择的改造方案分析

## 实施日期
2026-01-14

## 1. 当前因子演进流程分析

### 1.1 当前架构

**文件位置**：`rdagent/scenarios/qlib/developer/factor_runner.py`

**关键代码**（第314-363行）：

```python
# 第314-320行：检查是否存在SOTA模型
exist_sota_model_exp = False
for base_exp in reversed(exp.based_experiments):
    if isinstance(base_exp, QlibModelExperiment):
        sota_model_exp = base_exp
        exist_sota_model_exp = True
        break

# 第322-349行：如果存在SOTA模型，使用SOTA模型
if exist_sota_model_exp:
    exp.experiment_workspace.inject_files(
        **{"model.py": sota_model_exp.sub_workspace_list[0].file_dict["model.py"]}
    )
    env_to_use = {"PYTHONPATH": "./"}
    sota_training_hyperparameters = sota_model_exp.sub_tasks[0].training_hyperparameters
    if sota_training_hyperparameters:
        env_to_use.update({
            "n_epochs": str(sota_training_hyperparameters.get("n_epochs", "100")),
            "lr": str(sota_training_hyperparameters.get("lr", "2e-4")),
            "early_stop": str(sota_training_hyperparameters.get("early_stop", 10)),
            "batch_size": str(sota_training_hyperparameters.get("batch_size", 256)),
            "weight_decay": str(sota_training_hyperparameters.get("weight_decay", 0.0001)),
        })
    sota_model_type = sota_model_exp.sub_tasks[0].model_type
    if sota_model_type == "TimeSeries":
        env_to_use.update({
            "dataset_cls": "TSDatasetH", "num_features": num_features, "step_len": 20, "num_timesteps": 20
        })
    elif sota_model_type == "Tabular":
        env_to_use.update({"dataset_cls": "DatasetH", "num_features": num_features})

    # model + combined factors
    result, stdout = exp.experiment_workspace.execute(
        qlib_config_name="conf_combined_factors_sota_model.yaml", run_env=env_to_use
    )
else:
    # 第350-363行：否则使用默认的LGBM模型
    result, stdout = exp.experiment_workspace.execute(
        qlib_config_name=(
            f"conf_baseline.yaml" if len(exp.based_experiments) == 0 else "conf_combined_factors_dynamic.yaml"
        )
    )
```

### 1.2 当前模型选择机制

| 情况 | 使用的模型 | 配置文件 | 说明 |
|-----|-----------|---------|------|
| 有SOTA模型 | SOTA模型 | conf_combined_factors_sota_model.yaml | 使用SOTA模型的model.py和参数 |
| 无SOTA模型 | LGBM（默认） | conf_baseline.yaml 或 conf_combined_factors_dynamic.yaml | 使用固定的LGBM模型 |

### 1.3 当前限制

1. **模型选择单一**：没有SOTA模型时，只能使用LGBM模型
2. **缺乏灵活性**：无法根据因子特点选择合适的模型
3. **无模型对比**：无法对比不同模型的性能
4. **配置固定**：模型配置写死在配置文件中

## 2. 改造方案分析

### 方案1：简单的多模型轮询（推荐）

#### 2.1.1 方案描述

在因子演进时，如果没有SOTA模型，则轮询使用多个预设的模型进行测试。

#### 2.1.2 改造工作量

| 项目 | 工作量 | 说明 |
|-----|-------|------|
| 代码修改 | 50-80行 | 修改factor_runner.py |
| 配置文件 | 3-5个 | 创建多个模型配置文件 |
| 环境变量 | 1个 | 添加模型选择控制 |
| **总计** | **低（约100行）** | 1-2天完成 |

#### 2.1.3 需要修改的文件

**1. factor_runner.py**

```python
# 在第350-363行之前添加模型选择逻辑
def get_model_config_for_factor(exp: QlibFactorExperiment) -> str:
    """
    根据环境变量或轮询策略选择模型配置文件
    
    Returns:
        模型配置文件名
    """
    model_selection_mode = os.getenv("MODEL_SELECTION_MODE", "lgbm")
    
    # 模型配置映射
    model_configs = {
        "lgbm": "conf_baseline.yaml",
        "xgb": "conf_xgb_model.yaml",
        "rf": "conf_rf_model.yaml",
        "mlp": "conf_mlp_model.yaml",
    }
    
    if model_selection_mode == "rotate":
        # 轮询策略：基于实验ID选择模型
        exp_id = hash(str(exp.task.task_id)) % len(model_configs)
        model_keys = list(model_configs.keys())
        selected_model = model_keys[exp_id]
        logger.info(f"轮询选择模型: {selected_model}")
        return model_configs[selected_model]
    elif model_selection_mode in model_configs:
        return model_configs[model_selection_mode]
    else:
        # 默认使用LGBM
        return model_configs["lgbm"]

# 修改第350-363行
qlib_config_name = get_model_config_for_factor(exp)
result, stdout = exp.experiment_workspace.execute(
    qlib_config_name=qlib_config_name
)
```

**2. 创建新的模型配置文件**

需要创建以下配置文件：
- `conf_xgb_model.yaml`：XGBoost模型配置
- `conf_rf_model.yaml`：RandomForest模型配置
- `conf_mlp_model.yaml`：MLP模型配置

**示例：conf_xgb_model.yaml**

```yaml
task:
    model:
        class: XGBModel
        module_path: qlib.contrib.model.xgboost
        kwargs:
            objective: reg:squarederror
            eval_metric: rmse
            max_depth: 6
            learning_rate: 0.1
            n_estimators: 100
            subsample: 0.8
            colsample_bytree: 0.8
            n_jobs: 20
    dataset:
        class: DatasetH
        module_path: qlib.data.dataset
        kwargs:
            handler:
                class: Alpha158
                module_path: qlib.contrib.data.handler
                kwargs: *data_handler_config
            segments:
                train: [2010-01-07, 2018-12-31]
                valid: [2019-01-01, 2020-12-31]
                test: [2021-01-01, 2025-12-01]
```

**3. 环境变量配置**

在`.env`文件中添加：

```env
# 模型选择模式
# lgbm: 只使用LGBM（默认）
# xgb: 只使用XGBoost
# rf: 只使用RandomForest
# mlp: 只使用MLP
# rotate: 轮询使用所有模型
MODEL_SELECTION_MODE=lgbm
```

#### 2.1.4 优点

1. **改动量小**：只需修改约100行代码
2. **风险低**：不影响现有逻辑，只是扩展
3. **灵活性高**：通过环境变量控制，无需修改代码
4. **易于回退**：设置`MODEL_SELECTION_MODE=lgbm`即可回退

#### 2.1.5 缺点

1. **无智能选择**：只是轮询或固定选择，不根据因子特点选择
2. **无性能对比**：不同模型之间没有性能对比
3. **配置冗余**：需要维护多个配置文件

#### 2.1.6 预期效果

- **因子演进多样性**：不同轮次使用不同模型，增加探索空间
- **模型性能对比**：通过日志可以对比不同模型的性能
- **灵活性提升**：可以根据需要切换模型

---

### 方案2：基于性能的模型选择

#### 2.2.1 方案描述

在因子演进时，如果没有SOTA模型，则同时测试多个模型，选择性能最好的模型。

#### 2.2.2 改造工作量

| 项目 | 工作量 | 说明 |
|-----|-------|------|
| 代码修改 | 150-200行 | 修改factor_runner.py，添加并行测试逻辑 |
| 配置文件 | 3-5个 | 创建多个模型配置文件 |
| 性能记录 | 50-80行 | 添加模型性能记录机制 |
| 环境变量 | 2个 | 添加模型选择控制 |
| **总计** | **中等（约300行）** | 3-5天完成 |

#### 2.2.3 需要修改的文件

**1. factor_runner.py**

```python
def test_multiple_models(exp: QlibFactorExperiment, model_configs: list[str]) -> tuple[str, dict, str]:
    """
    测试多个模型，选择性能最好的
    
    Returns:
        (best_config_name, best_result, best_stdout)
    """
    best_result = None
    best_stdout = ""
    best_config_name = ""
    best_ic = -float('inf')
    
    for config_name in model_configs:
        logger.info(f"测试模型配置: {config_name}")
        try:
            result, stdout = exp.experiment_workspace.execute(
                qlib_config_name=config_name
            )
            
            if result is not None:
                ic = result.get("IC", -float('inf'))
                logger.info(f"模型 {config_name} IC: {ic}")
                
                if ic > best_ic:
                    best_ic = ic
                    best_result = result
                    best_stdout = stdout
                    best_config_name = config_name
        except Exception as e:
            logger.warning(f"模型 {config_name} 测试失败: {e}")
            continue
    
    if best_result is None:
        raise FactorEmptyError(f"所有模型测试失败")
    
    logger.info(f"选择最佳模型: {best_config_name}, IC: {best_ic}")
    return best_config_name, best_result, best_stdout

# 修改第350-363行
model_selection_mode = os.getenv("MODEL_SELECTION_MODE", "lgbm")

if model_selection_mode == "best":
    # 测试所有模型，选择最好的
    model_configs = [
        "conf_baseline.yaml",
        "conf_xgb_model.yaml",
        "conf_rf_model.yaml",
        "conf_mlp_model.yaml",
    ]
    qlib_config_name, result, stdout = test_multiple_models(exp, model_configs)
else:
    # 使用指定的模型
    qlib_config_name = get_model_config_for_factor(exp)
    result, stdout = exp.experiment_workspace.execute(
        qlib_config_name=qlib_config_name
    )
```

**2. 创建新的模型配置文件**

与方案1相同，需要创建多个模型配置文件。

**3. 环境变量配置**

```env
# 模型选择模式
# lgbm: 只使用LGBM（默认）
# xgb: 只使用XGBoost
# rf: 只使用RandomForest
# mlp: 只使用MLP
# rotate: 轮询使用所有模型
# best: 测试所有模型，选择性能最好的
MODEL_SELECTION_MODE=lgbm
```

#### 2.2.4 优点

1. **性能最优**：每次选择性能最好的模型
2. **自动化**：无需人工干预
3. **数据驱动**：基于实际性能选择

#### 2.2.5 缺点

1. **改动量大**：需要修改约300行代码
2. **时间成本高**：需要测试多个模型，因子演进时间增加3-4倍
3. **资源消耗大**：并行测试多个模型，内存和CPU消耗增加
4. **风险中等**：并行测试可能引入新的bug

#### 2.2.6 预期效果

- **性能提升**：每次选择性能最好的模型，IC预期提升5-10%
- **时间成本**：因子演进时间增加3-4倍
- **资源消耗**：内存和CPU消耗增加2-3倍

---

### 方案3：LLM推荐模型

#### 2.3.1 方案描述

在因子演进时，让LLM根据因子特点推荐合适的模型。

#### 2.3.2 改造工作量

| 项目 | 工作量 | 说明 |
|-----|-------|------|
| 代码修改 | 300-400行 | 修改factor_runner.py，添加LLM推荐接口 |
| 配置文件 | 3-5个 | 创建多个模型配置文件 |
| 提示词修改 | 50-100行 | 修改提示词，添加模型推荐逻辑 |
| 环境变量 | 2个 | 添加模型选择控制 |
| **总计** | **高（约500行）** | 5-7天完成 |

#### 2.3.3 需要修改的文件

**1. factor_runner.py**

```python
def recommend_model_by_llm(exp: QlibFactorExperiment) -> str:
    """
    使用LLM推荐模型
    
    Returns:
        模型配置文件名
    """
    # 获取因子信息
    factor_info = ""
    for implementation in exp.sub_workspace_list:
        if implementation and implementation.file_dict:
            factor_code = implementation.file_dict.get("factor.py", "")
            factor_info += f"\n{factor_code[:500]}...\n"
    
    # 构建提示词
    system_prompt = """
    你是一个量化金融专家，需要根据因子特点推荐合适的机器学习模型。
    
    可选模型：
    1. LGBM (LightGBM): 适合表格数据，训练速度快，内存占用低
    2. XGB (XGBoost): 适合表格数据，性能稳定，泛化能力强
    3. RF (RandomForest): 适合表格数据，抗过拟合能力强
    4. MLP (Multi-Layer Perceptron): 适合非线性关系，需要大量数据
    
    请根据因子特点，从以上模型中选择一个最合适的，只返回模型名称（lgbm/xgb/rf/mlp）。
    """
    
    user_prompt = f"""
    以下是因子的代码片段：
    {factor_info}
    
    请推荐最适合的模型。
    """
    
    try:
        resp = APIBackend().build_messages_and_create_chat_completion(
            user_prompt=user_prompt,
            system_prompt=system_prompt,
            json_mode=False,
        )
        
        if isinstance(resp, str):
            model_name = resp.strip().lower()
            model_configs = {
                "lgbm": "conf_baseline.yaml",
                "xgb": "conf_xgb_model.yaml",
                "rf": "conf_rf_model.yaml",
                "mlp": "conf_mlp_model.yaml",
            }
            
            if model_name in model_configs:
                logger.info(f"LLM推荐模型: {model_name}")
                return model_configs[model_name]
    except Exception as e:
        logger.warning(f"LLM推荐模型失败: {e}")
    
    # 默认使用LGBM
    return "conf_baseline.yaml"

# 修改第350-363行
model_selection_mode = os.getenv("MODEL_SELECTION_MODE", "lgbm")

if model_selection_mode == "llm":
    qlib_config_name = recommend_model_by_llm(exp)
else:
    qlib_config_name = get_model_config_for_factor(exp)

result, stdout = exp.experiment_workspace.execute(
    qlib_config_name=qlib_config_name
)
```

**2. 创建新的模型配置文件**

与方案1相同，需要创建多个模型配置文件。

**3. 环境变量配置**

```env
# 模型选择模式
# lgbm: 只使用LGBM（默认）
# xgb: 只使用XGBoost
# rf: 只使用RandomForest
# mlp: 只使用MLP
# rotate: 轮询使用所有模型
# best: 测试所有模型，选择性能最好的
# llm: 使用LLM推荐模型
MODEL_SELECTION_MODE=lgbm
```

#### 2.3.4 优点

1. **智能化**：根据因子特点推荐模型
2. **灵活性高**：可以适应不同类型的因子
3. **可扩展**：可以添加更多模型

#### 2.3.5 缺点

1. **改动量大**：需要修改约500行代码
2. **依赖LLM**：需要LLM API调用，增加成本
3. **不确定性**：LLM推荐结果可能不稳定
4. **风险高**：LLM推荐可能不准确，影响性能

#### 2.3.6 预期效果

- **智能化选择**：根据因子特点选择模型，可能提升性能
- **成本增加**：每次因子演进需要调用LLM API
- **不确定性**：LLM推荐结果可能不稳定

---

## 3. 方案对比

| 维度 | 方案1：轮询 | 方案2：性能选择 | 方案3：LLM推荐 |
|-----|----------|--------------|------------|
| **代码改动量** | 低（约100行） | 中等（约300行） | 高（约500行） |
| **实施时间** | 1-2天 | 3-5天 | 5-7天 |
| **技术风险** | 低 | 中等 | 高 |
| **时间成本** | 无增加 | 增加3-4倍 | 无增加 |
| **资源消耗** | 无增加 | 增加2-3倍 | 无增加 |
| **性能提升** | 中等（+3-5%） | 高（+5-10%） | 不确定（±5%） |
| **灵活性** | 高 | 低 | 高 |
| **智能化** | 低 | 低 | 高 |
| **可维护性** | 高 | 中等 | 低 |
| **回退难度** | 容易 | 中等 | 容易 |

## 4. 推荐方案

### 4.1 短期方案（1-2周）：方案1 - 简单的多模型轮询

**推荐理由**：
1. ✅ **改动量小**：只需修改约100行代码
2. ✅ **风险低**：不影响现有逻辑，只是扩展
3. ✅ **灵活性高**：通过环境变量控制，易于切换
4. ✅ **易于回退**：设置`MODEL_SELECTION_MODE=lgbm`即可回退
5. ✅ **实施快**：1-2天即可完成

**实施步骤**：
1. 修改`factor_runner.py`，添加模型选择逻辑（约50行）
2. 创建3-4个新的模型配置文件（约40行）
3. 添加环境变量配置（约10行）
4. 测试验证

**预期效果**：
- 因子演进多样性提升
- 不同轮次使用不同模型
- 可以通过日志对比不同模型的性能

### 4.2 中期方案（1-2个月）：方案2 - 基于性能的模型选择

**推荐理由**：
1. ✅ **性能最优**：每次选择性能最好的模型
2. ✅ **自动化**：无需人工干预
3. ✅ **数据驱动**：基于实际性能选择

**实施步骤**：
1. 先实施方案1，验证可行性
2. 添加并行测试逻辑（约150行）
3. 添加性能记录机制（约50行）
4. 测试验证

**预期效果**：
- 性能提升5-10%
- 时间成本增加3-4倍
- 资源消耗增加2-3倍

### 4.3 长期方案（3-6个月）：方案3 - LLM推荐模型

**推荐理由**：
1. ✅ **智能化**：根据因子特点推荐模型
2. ✅ **灵活性高**：可以适应不同类型的因子
3. ✅ **可扩展**：可以添加更多模型

**实施步骤**：
1. 先实施方案1和方案2，积累数据
2. 添加LLM推荐接口（约300行）
3. 修改提示词（约100行）
4. 测试验证

**预期效果**：
- 智能化选择模型
- 成本增加（LLM API调用）
- 不确定性较高

## 5. 实施建议

### 5.1 分阶段实施

**第一阶段（1-2天）**：
- 实施方案1：简单的多模型轮询
- 创建3个模型配置文件（XGBoost、RandomForest、MLP）
- 添加环境变量控制
- 测试验证

**第二阶段（1-2周）**：
- 运行一段时间，收集数据
- 分析不同模型的性能
- 根据结果决定是否实施方案2

**第三阶段（1-2个月）**：
- 如果方案1效果良好，实施方案2
- 添加并行测试逻辑
- 添加性能记录机制

**第四阶段（3-6个月）**：
- 如果方案2效果良好，考虑方案3
- 添加LLM推荐接口
- 优化提示词

### 5.2 风险控制

1. **环境变量控制**：通过环境变量控制模型选择，易于回退
2. **日志记录**：详细记录模型选择过程和性能，便于分析
3. **性能监控**：监控因子演进时间和资源消耗
4. **A/B测试**：先在小规模数据上测试，再应用到生产环境

### 5.3 成本评估

| 方案 | 开发成本 | 运行成本 | 总成本 |
|-----|---------|---------|-------|
| 方案1 | 低（1-2天） | 无 | 低 |
| 方案2 | 中等（3-5天） | 时间成本+3-4倍 | 中等 |
| 方案3 | 高（5-7天） | LLM API成本 | 高 |

## 6. 结论

### 6.1 可行性分析

**方案1（简单轮询）**：
- ✅ **完全可行**
- ✅ **改动量小**
- ✅ **风险低**
- ✅ **推荐优先实施**

**方案2（性能选择）**：
- ✅ **可行**
- ⚠️ **改动量中等**
- ⚠️ **时间成本高**
- ⚠️ **建议中期实施**

**方案3（LLM推荐）**：
- ⚠️ **可行但风险高**
- ⚠️ **改动量大**
- ⚠️ **不确定性高**
- ⚠️ **建议长期实施**

### 6.2 最终建议

**建议采用分阶段实施策略**：

1. **立即实施**（1-2天）：方案1 - 简单的多模型轮询
   - 改动量小（约100行）
   - 风险低
   - 易于回退
   - 可以快速验证效果

2. **中期实施**（1-2个月）：方案2 - 基于性能的模型选择
   - 如果方案1效果良好
   - 可以进一步提升性能
   - 但需要考虑时间成本

3. **长期实施**（3-6个月）：方案3 - LLM推荐模型
   - 如果方案2效果良好
   - 可以进一步提升智能化
   - 但需要考虑LLM API成本

### 6.3 预期收益

**方案1**：
- 因子演进多样性提升
- 不同模型性能对比
- IC预期提升3-5%

**方案2**：
- 性能最优
- IC预期提升5-10%
- 时间成本增加3-4倍

**方案3**：
- 智能化选择
- IC预期提升±5%
- LLM API成本增加

## 7. 附录

### 7.1 模型配置文件示例

**conf_xgb_model.yaml**：
```yaml
task:
    model:
        class: XGBModel
        module_path: qlib.contrib.model.xgboost
        kwargs:
            objective: reg:squarederror
            eval_metric: rmse
            max_depth: 6
            learning_rate: 0.1
            n_estimators: 100
            subsample: 0.8
            colsample_bytree: 0.8
            n_jobs: 20
    dataset:
        class: DatasetH
        module_path: qlib.data.dataset
        kwargs:
            handler:
                class: Alpha158
                module_path: qlib.contrib.data.handler
                kwargs: *data_handler_config
            segments:
                train: [2010-01-07, 2018-12-31]
                valid: [2019-01-01, 2020-12-31]
                test: [2021-01-01, 2025-12-01]
```

### 7.2 环境变量配置

```env
# 模型选择模式
# lgbm: 只使用LGBM（默认）
# xgb: 只使用XGBoost
# rf: 只使用RandomForest
# mlp: 只使用MLP
# rotate: 轮询使用所有模型
# best: 测试所有模型，选择性能最好的
# llm: 使用LLM推荐模型
MODEL_SELECTION_MODE=lgbm
```

### 7.3 回滚方法

如果需要回退到原始行为，只需设置环境变量：

```bash
export MODEL_SELECTION_MODE=lgbm
```

或者修改代码，删除模型选择逻辑。

## 8. 联系人

如有问题，请联系开发团队。

## 9. 版本历史

| 版本 | 日期 | 说明 |
|-----|------|------|
| v1.0 | 2026-01-14 | 初始版本，分析因子演进中增加模型选择的改造方案 |
