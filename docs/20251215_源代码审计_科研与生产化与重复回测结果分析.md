# 20251215_源代码审计_科研与生产化与重复回测结果分析

## 0. 结论概览

- 本程序（RD-Agent + Qlib 场景）**主要是“科研/自动化研究”导向**：核心目标是让 LLM 生成假设/代码并在 Qlib 回测闭环中快速迭代，而不是直接面向稳定的生产交易系统。
- 若要用于实际应用（模拟盘/实盘/长期运营），需要补齐：**结果可复现与可审计的产物协议、配置/数据版本锁定、任务编排与资源治理、策略 IR 与多引擎适配层、线上风控与执行**等。
- 你近期的改动（去重放宽、因子提示词加强、RAG 知识卡片、共享 KB 架构规划）**是在朝“生产化可用/可控”方向演进**，但目前仍主要集中在“让研究环更稳定、减少幻觉与失败”这一层。
- 多轮任务/不同 loop 出现“相同回测结果”，从源码逻辑上存在多个高概率根因，其中有一个属于**设计缺陷级别**：`read_exp_res.py` 在 Qlib 侧取“全局最新 recorder”，可能导致**读取到非本次 qrun 的结果**，从而跨 loop 得到相同（或错配）的回测指标。

## 1) 本程序是否为纯科研目的？（从源码结构推断）

### 1.1 工作流定位

从 `rdagent/components/workflow/rd_loop.py` 与 `rdagent/utils/workflow/loop.py` 可以看到：

- 核心链路是 `propose -> exp_gen -> coding -> running -> feedback -> record`（record 在 LoopBase 内部固化）。
- loop/session 的设计重点是：

- 可暂停/恢复（`__session__` pickled session）。
- 允许并行 loop（`RD_AGENT_SETTINGS.step_semaphore`）。
- LLM 迭代式改代码并在模拟环境中验证。

这些都非常符合“自动化研究/实验编排”而非生产交易。

### 1.2 执行环境与产物设计

- 使用 `FBWorkspace`（文件夹式 workspace）+ `Env`（docker/conda/local）去运行。
- 大量使用 `pickle_cache` 加速重复计算（研发效率优先）。
- 结果主要通过日志与 workspace 文件读回（例如 `qlib_res.csv`, `ret.pkl`），而不是通过稳定的外部接口/数据库。

这些特征也更像科研/实验平台。

### 1.3 缺少生产系统必备的“契约层”

生产系统通常要求：

- 标准化的结果导出（JSON schema）与审计字段。
- 明确的数据版本与配置锁定。
- 策略上线前的验收流程、风控、执行与回滚。

当前仓库虽有部分方向性设计（docs 中有集成规范），但代码层面尚未形成“生产契约/产物协议”的强约束。

**结论**：不是“纯科研”，但**以科研/自动化研究为主**；生产化能力尚不完整。

## 2) 若作为实际应用（模拟盘/实盘/策略中台），需要解决哪些问题？

下面按“必须补齐”的维度列出（从源码现状对照）。

### 2.1 可复现/可审计（Production-grade reproducibility）

现状：

- workspace 使用随机 uuid 路径（`FBWorkspace.workspace_path = .../uuid`），缺少稳定的 run_id->输入/输出映射。
- 多层缓存会导致“看起来跑了，实际复用了旧结果”；缺少强制记录 cache 命中情况的机制（只能开 `QLIB_QUANT_CACHE_DEBUG=1` 部分看到）。
- Qlib 结果读取逻辑有跨 experiment 混淆风险（详见第 4 点）。

需要改进：

- 每次运行生成 `run_meta.json`：包含 git commit、数据版本、yaml 配置 hash、静态因子 parquet hash、随机种子、env 信息。
- 所有关键产物（因子列表、combined_factors parquet、model.py、yaml、指标 csv）需要有统一导出目录。
- 把“cache 命中/未命中”变成显式指标并写入 meta。

### 2.2 数据/配置版本治理

现状：

- YAML 内部写死了 provider_uri、static_path 等绝对路径（示例：`/mnt/c/Users/...`）。迁移磁盘/部署时非常脆弱。
- 缺少统一的数据 profile（字段白名单/可用字段来源）作为运行前置条件。

需要改进：

- 用环境变量/配置层统一 provider_uri、static_path，并产出 `data_profile.json`（字段集合、缺失率、覆盖率）。
- 对静态因子表、字段映射表做版本化（manifest）。

### 2.3 策略中台与多引擎接入

现状：

- RD-Agent 假设输出是“研究结论/代码”，并不是稳定的“策略包”。

需要改进：

- AIstock 侧建议产出 `strategy_ir.json`（策略中间表示），由不同引擎 adapter 转换为：

- RD-Agent/Qlib 配置
- 其他策略引擎配置
- 实盘执行配置

- RAG 需要分层：`kb/core`（通用规则）+ `kb/engines/*`（引擎专用）。

### 2.4 模拟盘/实盘需要的交易与风控闭环

现状：

- Qlib 回测策略（TopkDropoutStrategy 等）更多是研究评估，不等价于真实交易执行。
- 实盘需要：撮合、委托、滑点、风控、T+1、涨跌停处理、持仓与资金管理、监控告警。

需要改进：

- 策略包必须包含风险约束（仓位、行业暴露、最大回撤阈值、停牌/涨跌停处理）。
- 需要独立的执行层服务（不建议在 RD-Agent 内部硬做）。

## 3) 当前改动是否在朝第 2 点演进？

你近期改动（从代码与新增 RAG 文档可见）主要提升了：

- **研究环有效性**：

- 放宽因子去重（避免新因子全被丢弃）。
- 提示词强约束（要求更多静态/资金流因子）。
- 增加因子 AutoRepair（针对缺列/全 NaN 等失败模式）。

- **可控性与事实一致性**：

- 新增 `RAG/` 知识卡片，沉淀字段口径、失败模式、实现契约。
- 规划共享 KB/Index 的多租户模型（对未来多策略来源很关键）。

但从“生产化”角度看，目前还缺：

- 统一 run_id/产物协议（json schema）
- 配置/数据版本化与审计落盘
- 结果读取与缓存的强一致性（避免错读/复用导致误判）

**结论**：方向正确，但仍偏“研究平台稳定化”，生产化尚需关键结构性补齐。

## 4) 从程序逻辑/工作流角度解释：为何多轮/不同 loop 会得到相同回测结果？

这里不依赖日志，而基于源码指出“可能导致相同结果”的机制链条。

### 4.1 高风险根因 A：`read_exp_res.py` 取的是“全局最新 recorder”，不是“本次 qrun 的 recorder”（错读结果）

文件：`rdagent/scenarios/qlib/experiment/factor_template/read_exp_res.py`

关键逻辑：

- `R.list_experiments()` 列出所有 experiments
- 遍历所有 experiment 的 recorder，选择 `end_time` 最大的 recorder 作为 `latest_recorder`
- 从 `latest_recorder.list_metrics()` 导出 `qlib_res.csv` 并 load `portfolio_analysis/report_normal_1day.pkl` -> `ret.pkl`

这意味着：

- 如果 Qlib 的 recorder 存储（mlruns）是共享的（很常见），那么**本次 workspace 执行的 qrun 产物未必是全局最新**。
- 在并行 loop 或其他进程同时跑 qrun 的情况下，`latest_recorder` 很容易指向“别的 run”。

结果：

- 不同 loop 可能读到同一个“最新 recorder”，表现为指标完全一致。

这属于“系统性设计缺陷”，优先级应最高。

### 4.2 高风险根因 B：多层缓存导致 runner/环境直接复用旧结果

本仓库存在至少三层与结果复用相关的缓存：

#### (1) Runner 级缓存：`cache_with_pickle` + `CachedRunner.get_cache_key`

- `CachedRunner.get_cache_key` 默认只用 `Task.get_task_information()` 构造 hash。
- Qlib runner（你已修改）把 `factor.py`/`model.py` 源码与 `combined_factors_df.parquet` 的签名加入 key，这本身是对的。

但：

- 如果 `RD_AGENT_SETTINGS.cache_with_pickle=True`（默认 True），任何 key 碰撞/任务信息不变都会导致结果复用。
- 另外，factor 的执行（`FactorFBWorkspace.execute`）也用 `cache_with_pickle`，其 key 仅包含 `data_type + factor.py`（不包含数据内容/字段表版本）。

#### (2) 环境执行级缓存：`Env.cached_run`

文件：`rdagent/utils/env.py`

- `Env.run()` 如果 `self.conf.enable_cache=True`，会走 `cached_run()`。
- `cached_run` 的 key 当前包含：

- `local_path` 下所有 `*.py` 与 `*.csv` 文件内容
- entry 与 volume 信息
- `self.conf.extra_volumes`

- 但 key **不包含** `*.yaml`、`*.parquet`、以及更重要的 `combined_factors_df.parquet`（因为它是 parquet）。

结论：

- 即使不同 loop 写入了新的 `conf_*.yaml` 或新的 `combined_factors_df.parquet`，只要 `*.py/*.csv` 没变，环境层可能仍会命中旧缓存并把旧 zip 解压回 workspace。
- 这会让 qrun 的输出与 `qlib_res.csv/ret.pkl` 长期保持不变。

注意：当前 QlibCondaConf / QlibDockerConf 对 `enable_cache` 默认是 False，但 `EnvConf.enable_cache` 默认 True，且 `get_model_env/get_factor_env` 接口允许外部开启/继承 enable_cache。不同运行路径下可能会开启该缓存。

### 4.3 中风险根因 C：因子去重/列去重导致“特征库不变”

文件：`rdagent/scenarios/qlib/developer/factor_runner.py`

- 去重逻辑：用 IC 阈值（0.995）过滤高度相似因子。
- 你已修改为“如果全部被判相似，则保留全部新因子”。这降低了“特征库不变”的概率。

但仍可能出现：

- 新因子真实有效列数很少（大量 NaN 或与 SOTA 完全同构），最终 `combined_factors = concat(...).dropna()` 会丢掉很多行，甚至导致训练有效样本相近，从而模型表现接近。
- `combined_factors = combined_factors.loc[:, ~combined_factors.columns.duplicated(keep="last")]`：如果列名冲突，新列会覆盖旧列或被去掉，导致实际输入不变。

### 4.4 中风险根因 D：固定分段/固定回测区间 + 强势 SOTA 特征主导

从 YAML 看：

- segments 与 backtest 时间段固定。
- baseline 仍包含一套固定 Alpha158 feature 列表，combined_factors 也保留 alpha 特征。

如果新增因子对模型增益很小（或者被处理器/归一化削弱），最终策略指标可能非常接近。

但“完全一样”更多提示 A/B 类机制（错读/复用）。

## 5) 建议的修复与改进清单（按优先级）

### P0（必须优先修）

- `read_exp_res.py` 必须改为：读取“本次 qrun 对应的 recorder”。建议方案：

- 在 qrun 前设置唯一 `experiment_name/recorder_name`（由 workspace/run_id 派生），并在 read_exp_res.py 中只查该 experiment。
- 或者直接读取 workspace 内部生成的确定性产物（如果 qrun 能输出固定路径的 metrics）。

- 把 cache 命中信息写入日志/元数据：runner 缓存、env 缓存都应显式记录 HIT/MISS 与 key。

### P1（生产化方向）

- 统一产物协议：`run_meta.json`、`experiment_summary.json`、`strategy_ir.json`（AIstock 侧）。
- 配置与数据版本锁定：provider_uri、static_path、field map/whitelist 的版本化。

### P2（效率与可靠性）

- 对因子新列做 preflight：列存在检查 + NaN 比例阈值 + 输出分布检查。
- 将失败模式与修复策略结构化（不仅日志文本），便于 AutoRepair 与 RAG 召回。

## 6) 补充：本次审计对“迁移/共享 RAG/多引擎接入”的启示

- 由于存在多层缓存与 workspace 随机路径，迁移到新盘时应把：

- `pickle_cache/`、`git_ignore_folder/RD-Agent_workspace/` 与 `log/` 分离到共享域（quant_artifacts），并做版本/清理策略。

- 共享 RAG 的 KB 应分层，并与 Index 分命名空间，避免不同引擎互相污染召回。

